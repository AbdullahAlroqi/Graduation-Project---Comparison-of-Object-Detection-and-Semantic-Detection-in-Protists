{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ek_mcGYIGzpN",
        "RGL04PCnHH_y"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek_mcGYIGzpN"
      },
      "source": [
        "# Import the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn3pS-NeKvV1"
      },
      "source": [
        "!wget -q https://www.dropbox.com/s/8conv524x6xid27/dataset.tar.bz2?dl=0 && mv \"dataset.tar.bz2?dl=0\" \"dataset.tar.bz2\" && tar -jxf dataset.tar.bz2 && rm dataset.tar.bz2\n",
        "!wget -q https://www.dropbox.com/s/5kcxh2dcjtn35k7/Object.csv?dl=0 && mv \"Object.csv?dl=0\" \"Object.csv\"\n",
        "!wget -q https://www.dropbox.com/s/7bfw646mpadynt2/Semantic.csv?dl=0 && mv \"Semantic.csv?dl=0\" \"Semantic.csv\"\n",
        "!mkdir dataset/Ori\n",
        "!mkdir dataset/Train\n",
        "!mkdir dataset/Annotations\n",
        "!mkdir dataset/Valid\n",
        "!mkdir dataset/Valid_Annotations\n",
        "!mv dataset/*.jpg dataset/Ori\n",
        "!rm -r sample_data/"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG5UtnQDHR51"
      },
      "source": [
        "!rm dataset/Ori/Colsterium*\n",
        "!rm dataset/Ori/Cylindrocystis*\n",
        "!rm dataset/Ori/Lepocinclis*\n",
        "!rm dataset/Ori/Micrasterias*\n",
        "#!rm dataset/Ori/Paramecium_b*\n",
        "!rm dataset/Ori/Peridinium*\n",
        "!rm dataset/Ori/Pinnularia*\n",
        "!rm dataset/Ori/Pleurotaenium*\n",
        "!rm dataset/Ori/Pyrocystis*\n",
        "!rm dataset/Ori/Volvox*\n",
        "!rm dataset/Ori/Ceratium*\n",
        "!rm dataset/Ori/Coleps*\n",
        "!rm dataset/Ori/Collodictyon*\n",
        "!rm dataset/Ori/Didinium*\n",
        "!rm dataset/Ori/Dinobryon*\n",
        "!rm dataset/Ori/Frontonia*\n",
        "!rm dataset/Ori/Paramecium\\ s*\n",
        "!rm dataset/Ori/Phacus*"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSKJ_dDp042Y"
      },
      "source": [
        "!grep Paramecium_b Object.csv > object.csv"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGL04PCnHH_y"
      },
      "source": [
        "# Augment object images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgxBwgbpZpYG"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "from keras.preprocessing.image import array_to_img\n",
        "\n",
        "def draw_rect(im, cords, color = None):\n",
        "\tim = im.copy()\n",
        "\tcords = cords[:,:4]\n",
        "\tcords = cords.reshape(-1,4)\n",
        "\tif not color:\n",
        "\t\tcolor = [255,255,255]\n",
        "\tfor cord in cords:\n",
        "\t\tpt1, pt2 = (cord[0], cord[1]) , (cord[2], cord[3])\n",
        "\t\tpt1 = int(pt1[0]), int(pt1[1])\n",
        "\t\tpt2 = int(pt2[0]), int(pt2[1])\n",
        "\t\tim = cv2.rectangle(im.copy(), pt1, pt2, color, int(max(im.shape[:2])/200))\n",
        "\treturn im\n",
        "\n",
        "def bbox_area(bbox):\n",
        "\treturn (bbox[:,2] - bbox[:,0])*(bbox[:,3] - bbox[:,1])\n",
        "\t\t\n",
        "def clip_box(bbox, clip_box, alpha):\n",
        "\tar_ = (bbox_area(bbox))\n",
        "\tx_min = np.maximum(bbox[:,0], clip_box[0]).reshape(-1,1)\n",
        "\ty_min = np.maximum(bbox[:,1], clip_box[1]).reshape(-1,1)\n",
        "\tx_max = np.minimum(bbox[:,2], clip_box[2]).reshape(-1,1)\n",
        "\ty_max = np.minimum(bbox[:,3], clip_box[3]).reshape(-1,1)\n",
        "\tbbox = np.hstack((x_min, y_min, x_max, y_max, bbox[:,4:]))\n",
        "\tdelta_area = ((ar_ - bbox_area(bbox))/ar_)\n",
        "\tmask = (delta_area < (1 - alpha)).astype(int)\n",
        "\tbbox = bbox[mask == 1,:]\n",
        "\treturn bbox\n",
        "\n",
        "def rotate_im(image, angle):\n",
        "\t(h, w) = image.shape[:2]\n",
        "\t(cX, cY) = (w // 2, h // 2)\n",
        "\tM = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
        "\tcos = np.abs(M[0, 0])\n",
        "\tsin = np.abs(M[0, 1])\n",
        "\tnW = int((h * sin) + (w * cos))\n",
        "\tnH = int((h * cos) + (w * sin))\n",
        "\tM[0, 2] += (nW / 2) - cX\n",
        "\tM[1, 2] += (nH / 2) - cY\n",
        "\timage = cv2.warpAffine(image, M, (nW, nH))\n",
        "\treturn image\n",
        "\n",
        "def get_corners(bboxes):\n",
        "\twidth = (bboxes[:,2] - bboxes[:,0]).reshape(-1,1)\n",
        "\theight = (bboxes[:,3] - bboxes[:,1]).reshape(-1,1)\n",
        "\tx1 = bboxes[:,0].reshape(-1,1)\n",
        "\ty1 = bboxes[:,1].reshape(-1,1)\n",
        "\tx2 = x1 + width\n",
        "\ty2 = y1 \n",
        "\tx3 = x1\n",
        "\ty3 = y1 + height\n",
        "\tx4 = bboxes[:,2].reshape(-1,1)\n",
        "\ty4 = bboxes[:,3].reshape(-1,1)\n",
        "\tcorners = np.hstack((x1,y1,x2,y2,x3,y3,x4,y4))\n",
        "\treturn corners\n",
        "\n",
        "def rotate_box(corners,angle,  cx, cy, h, w):\n",
        "\tcorners = corners.reshape(-1,2)\n",
        "\tcorners = np.hstack((corners, np.ones((corners.shape[0],1), dtype = type(corners[0][0]))))\n",
        "\tM = cv2.getRotationMatrix2D((cx, cy), angle, 1.0)\n",
        "\tcos = np.abs(M[0, 0])\n",
        "\tsin = np.abs(M[0, 1])\n",
        "\tnW = int((h * sin) + (w * cos))\n",
        "\tnH = int((h * cos) + (w * sin))\n",
        "\t# adjust the rotation matrix to take into account translation\n",
        "\tM[0, 2] += (nW / 2) - cx\n",
        "\tM[1, 2] += (nH / 2) - cy\n",
        "\t# Prepare the vector to be transformed\n",
        "\tcalculated = np.dot(M,corners.T).T\n",
        "\tcalculated = calculated.reshape(-1,8)\n",
        "\treturn calculated\n",
        "\n",
        "def get_enclosing_box(corners):\n",
        "\tx_ = corners[:,[0,2,4,6]]\n",
        "\ty_ = corners[:,[1,3,5,7]]\n",
        "\txmin = np.min(x_,1).reshape(-1,1)\n",
        "\tymin = np.min(y_,1).reshape(-1,1)\n",
        "\txmax = np.max(x_,1).reshape(-1,1)\n",
        "\tymax = np.max(y_,1).reshape(-1,1)\n",
        "\tfinal = np.hstack((xmin, ymin, xmax, ymax,corners[:,8:]))\n",
        "\treturn final\n",
        "\n",
        "def letterbox_image(img, inp_dim):\n",
        "\tinp_dim = (inp_dim, inp_dim)\n",
        "\timg_w, img_h = img.shape[1], img.shape[0]\n",
        "\tw, h = inp_dim\n",
        "\tnew_w = int(img_w * min(w/img_w, h/img_h))\n",
        "\tnew_h = int(img_h * min(w/img_w, h/img_h))\n",
        "\tresized_image = cv2.resize(img, (new_w,new_h))\n",
        "\tcanvas = np.full((inp_dim[1], inp_dim[0], 3), 0)\n",
        "\tcanvas[(h-new_h)//2:(h-new_h)//2 + new_h,(w-new_w)//2:(w-new_w)//2 + new_w,  :] = resized_image\n",
        "\treturn canvas\n",
        "\n",
        "class RandomHorizontalFlip(object):\n",
        "\tdef __init__(self, p=0.5):\n",
        "\t\tself.p = p\n",
        "\tdef __call__(self, img, bboxes):\n",
        "\t\t\timg_center = np.array(img.shape[:2])[::-1]/2\n",
        "\t\t\timg_center = np.hstack((img_center, img_center))\n",
        "\t\t\tif random.random() < self.p:\n",
        "\t\t\t\timg = img[:, ::-1, :]\n",
        "\t\t\t\tbboxes[:, [0, 2]] += 2*(img_center[[0, 2]] - bboxes[:, [0, 2]])\n",
        "\t\t\t\tbox_w = abs(bboxes[:, 0] - bboxes[:, 2])\n",
        "\t\t\t\tbboxes[:, 0] -= box_w\n",
        "\t\t\t\tbboxes[:, 2] += box_w\n",
        "\t\t\treturn img, bboxes\n",
        "\n",
        "class HorizontalFlip(object):\n",
        "\tdef __init__(self):\n",
        "\t\tpass\n",
        "\tdef __call__(self, img, bboxes):\n",
        "\t\timg_center = np.array(img.shape[:2])[::-1]/2\n",
        "\t\timg_center = np.hstack((img_center, img_center))\n",
        "\t\timg = img[:, ::-1, :]\n",
        "\t\tbboxes[:, [0, 2]] += 2*(img_center[[0, 2]] - bboxes[:, [0, 2]])\n",
        "\t\tbox_w = abs(bboxes[:, 0] - bboxes[:, 2])\n",
        "\t\tbboxes[:, 0] -= box_w\n",
        "\t\tbboxes[:, 2] += box_w\n",
        "\t\treturn img, bboxes\n",
        "\n",
        "class RandomVerticalFlip(object):\n",
        "\tdef __init__(self, p=0.5):\n",
        "\t\tself.p = p\n",
        "\tdef __call__(self, img, bboxes):\n",
        "\t\t\timg_center = np.array(img.shape[:2])[::-1]/2\n",
        "\t\t\timg_center = np.hstack((img_center, img_center))\n",
        "\t\t\tif random.random() < self.p:\n",
        "\t\t\t\timg = img[::-1, :, :]\n",
        "\t\t\t\tbboxes[:, [1, 3]] += 2*(img_center[[1, 3]] - bboxes[:, [1, 3]])\n",
        "\t\t\t\tbox_h = abs(bboxes[:, 1] - bboxes[:, 3])\n",
        "\t\t\t\tbboxes[:, 1] -= box_h\n",
        "\t\t\t\tbboxes[:, 3] += box_h\n",
        "\t\t\treturn img, bboxes\n",
        "\n",
        "class VerticalFlip(object):\n",
        "\tdef __init__(self):\n",
        "\t\tpass\n",
        "\tdef __call__(self, img, bboxes):\n",
        "\t\timg_center = np.array(img.shape[:2])[::-1]/2\n",
        "\t\timg_center = np.hstack((img_center, img_center))\n",
        "\t\timg = img[::-1, :, :]\n",
        "\t\tbboxes[:, [1, 3]] += 2*(img_center[[1, 3]] - bboxes[:, [1, 3]])\n",
        "\t\tbox_h = abs(bboxes[:, 1] - bboxes[:, 3])\n",
        "\t\tbboxes[:, 1] -= box_h\n",
        "\t\tbboxes[:, 3] += box_h\n",
        "\t\treturn img, bboxes\n",
        "\n",
        "class RandomScale(object):\n",
        "\tdef __init__(self, scale = 0.2, diff = False):\n",
        "\t\tself.scale = scale\n",
        "\t\tif type(self.scale) == tuple:\n",
        "\t\t\tassert len(self.scale) == 2, \"Invalid range\"\n",
        "\t\t\tassert self.scale[0] > -1, \"Scale factor can't be less than -1\"\n",
        "\t\t\tassert self.scale[1] > -1, \"Scale factor can't be less than -1\"\n",
        "\t\telse:\n",
        "\t\t\tassert self.scale > 0, \"Please input a positive float\"\n",
        "\t\t\tself.scale = (max(-1, -self.scale), self.scale)\n",
        "\t\tself.diff = diff\n",
        "\tdef __call__(self, img, bboxes):\n",
        "\t\t#Chose a random digit to scale by \n",
        "\t\timg_shape = img.shape\n",
        "\t\tif self.diff:\n",
        "\t\t\tscale_x = random.uniform(*self.scale)\n",
        "\t\t\tscale_y = random.uniform(*self.scale)\n",
        "\t\telse:\n",
        "\t\t\tscale_x = random.uniform(*self.scale)\n",
        "\t\t\tscale_y = scale_x\n",
        "\t\tresize_scale_x = 1 + scale_x\n",
        "\t\tresize_scale_y = 1 + scale_y\n",
        "\t\timg=  cv2.resize(img, None, fx = resize_scale_x, fy = resize_scale_y)\n",
        "\t\tbboxes[:,:4] *= [resize_scale_x, resize_scale_y, resize_scale_x, resize_scale_y]\n",
        "\t\tcanvas = np.zeros(img_shape, dtype = np.uint8)\n",
        "\t\ty_lim = int(min(resize_scale_y,1)*img_shape[0])\n",
        "\t\tx_lim = int(min(resize_scale_x,1)*img_shape[1])\n",
        "\t\tcanvas[:y_lim,:x_lim,:] =  img[:y_lim,:x_lim,:]\n",
        "\t\timg = canvas\n",
        "\t\tbboxes = clip_box(bboxes, [0,0,1 + img_shape[1], img_shape[0]], 0.25)\n",
        "\t\treturn img, bboxes\n",
        "\n",
        "class Scale(object):\n",
        "\tdef __init__(self, scale_x = 0.2, scale_y = 0.2):\n",
        "\t\tself.scale_x = scale_x\n",
        "\t\tself.scale_y = scale_y\n",
        "\tdef __call__(self, img, bboxes):\n",
        "\t\t#Chose a random digit to scale by \n",
        "\t\timg_shape = img.shape\n",
        "\t\tresize_scale_x = 1 + self.scale_x\n",
        "\t\tresize_scale_y = 1 + self.scale_y\n",
        "\t\timg=  cv2.resize(img, None, fx = resize_scale_x, fy = resize_scale_y)\n",
        "\t\tbboxes[:,:4] *= [resize_scale_x, resize_scale_y, resize_scale_x, resize_scale_y]\n",
        "\t\tcanvas = np.zeros(img_shape, dtype = np.uint8)\n",
        "\t\ty_lim = int(min(resize_scale_y,1)*img_shape[0])\n",
        "\t\tx_lim = int(min(resize_scale_x,1)*img_shape[1])\n",
        "\t\tcanvas[:y_lim,:x_lim,:] =  img[:y_lim,:x_lim,:]\n",
        "\t\timg = canvas\n",
        "\t\tbboxes = clip_box(bboxes, [0,0,1 + img_shape[1], img_shape[0]], 0.25)\n",
        "\t\treturn img, bboxes\n",
        "\n",
        "class RandomTranslate(object):\n",
        "\tdef __init__(self, translate = 0.2, diff = False):\n",
        "\t\tself.translate = translate\n",
        "\t\tif type(self.translate) == tuple:\n",
        "\t\t\tassert len(self.translate) == 2, \"Invalid range\"\n",
        "\t\t\tassert self.translate[0] > 0 & self.translate[0] < 1\n",
        "\t\t\tassert self.translate[1] > 0 & self.translate[1] < 1\n",
        "\t\telse:\n",
        "\t\t\tassert self.translate > 0 and self.translate < 1\n",
        "\t\t\tself.translate = (-self.translate, self.translate)\n",
        "\t\tself.diff = diff\n",
        "\tdef __call__(self, img, bboxes):\n",
        "\t\timg_shape = img.shape\n",
        "\t\ttranslate_factor_x = random.uniform(*self.translate)\n",
        "\t\ttranslate_factor_y = random.uniform(*self.translate)\n",
        "\t\tif not self.diff:\n",
        "\t\t\ttranslate_factor_y = translate_factor_x\n",
        "\t\tcanvas = np.zeros(img_shape).astype(np.uint8)\n",
        "\t\tcorner_x = int(translate_factor_x*img.shape[1])\n",
        "\t\tcorner_y = int(translate_factor_y*img.shape[0])\n",
        "\t\torig_box_cords =  [max(0,corner_y), max(corner_x,0), min(img_shape[0], corner_y + img.shape[0]), min(img_shape[1],corner_x + img.shape[1])]\n",
        "\t\tmask = img[max(-corner_y, 0):min(img.shape[0], -corner_y + img_shape[0]), max(-corner_x, 0):min(img.shape[1], -corner_x + img_shape[1]),:]\n",
        "\t\tcanvas[orig_box_cords[0]:orig_box_cords[2], orig_box_cords[1]:orig_box_cords[3],:] = mask\n",
        "\t\timg = canvas\n",
        "\t\tbboxes[:,:4] += [corner_x, corner_y, corner_x, corner_y]\n",
        "\t\tbboxes = clip_box(bboxes, [0,0,img_shape[1], img_shape[0]], 0.25)\n",
        "\t\treturn img, bboxes\n",
        "\n",
        "class Translate(object):\n",
        "\tdef __init__(self, translate_x = 0.2, translate_y = 0.2, diff = False):\n",
        "\t\tself.translate_x = translate_x\n",
        "\t\tself.translate_y = translate_y\n",
        "\t\tassert self.translate_x > 0 and self.translate_x < 1\n",
        "\t\tassert self.translate_y > 0 and self.translate_y < 1\n",
        "\tdef __call__(self, img, bboxes):\n",
        "\t\timg_shape = img.shape\n",
        "\t\ttranslate_factor_x = self.translate_x\n",
        "\t\ttranslate_factor_y = self.translate_y\n",
        "\t\tcanvas = np.zeros(img_shape).astype(np.uint8)\n",
        "\t\tcorner_x = int(translate_factor_x*img.shape[1])\n",
        "\t\tcorner_y = int(translate_factor_y*img.shape[0])\n",
        "\t\torig_box_cords =  [max(0,corner_y), max(corner_x,0), min(img_shape[0], corner_y + img.shape[0]), min(img_shape[1],corner_x + img.shape[1])]\n",
        "\t\tmask = img[max(-corner_y, 0):min(img.shape[0], -corner_y + img_shape[0]), max(-corner_x, 0):min(img.shape[1], -corner_x + img_shape[1]),:]\n",
        "\t\tcanvas[orig_box_cords[0]:orig_box_cords[2], orig_box_cords[1]:orig_box_cords[3],:] = mask\n",
        "\t\timg = canvas\n",
        "\t\tbboxes[:,:4] += [corner_x, corner_y, corner_x, corner_y]\n",
        "\t\tbboxes = clip_box(bboxes, [0,0,img_shape[1], img_shape[0]], 0.25)\n",
        "\t\treturn img, bboxes\n",
        "\t\n",
        "class RandomRotate(object):\n",
        "\tdef __init__(self, angle = 10):\n",
        "\t\tself.angle = angle\n",
        "\t\tif type(self.angle) == tuple:\n",
        "\t\t\tassert len(self.angle) == 2, \"Invalid range\"  \n",
        "\t\telse:\n",
        "\t\t\tself.angle = (-self.angle, self.angle)\n",
        "\tdef __call__(self, img, bboxes):\n",
        "\t\tangle = random.uniform(*self.angle)\n",
        "\t\tw,h = img.shape[1], img.shape[0]\n",
        "\t\tcx, cy = w//2, h//2\n",
        "\t\timg = rotate_im(img, angle)\n",
        "\t\tcorners = get_corners(bboxes)\n",
        "\t\tcorners = np.hstack((corners, bboxes[:,4:]))\n",
        "\t\tcorners[:,:8] = rotate_box(corners[:,:8], angle, cx, cy, h, w)\n",
        "\t\tnew_bbox = get_enclosing_box(corners)\n",
        "\t\tscale_factor_x = img.shape[1] / w\n",
        "\t\tscale_factor_y = img.shape[0] / h\n",
        "\t\timg = cv2.resize(img, (w,h))\n",
        "\t\tnew_bbox[:,:4] /= [scale_factor_x, scale_factor_y, scale_factor_x, scale_factor_y] \n",
        "\t\tbboxes\t= new_bbox\n",
        "\t\tbboxes = clip_box(bboxes, [0,0,w, h], 0.25)\n",
        "\t\treturn img, bboxes\n",
        "\n",
        "class Rotate(object):\n",
        "\tdef __init__(self, angle):\n",
        "\t\tself.angle = angle\n",
        "\tdef __call__(self, img, bboxes):\n",
        "\t\tangle = self.angle\n",
        "\t\tprint(self.angle)\n",
        "\t\tw,h = img.shape[1], img.shape[0]\n",
        "\t\tcx, cy = w//2, h//2\n",
        "\t\tcorners = get_corners(bboxes)\n",
        "\t\tcorners = np.hstack((corners, bboxes[:,4:]))\n",
        "\t\timg = rotate_im(img, angle)\n",
        "\t\tcorners[:,:8] = rotate_box(corners[:,:8], angle, cx, cy, h, w)\n",
        "\t\tnew_bbox = get_enclosing_box(corners)\n",
        "\t\tscale_factor_x = img.shape[1] / w\n",
        "\t\tscale_factor_y = img.shape[0] / h\n",
        "\t\timg = cv2.resize(img, (w,h))\n",
        "\t\tnew_bbox[:,:4] /= [scale_factor_x, scale_factor_y, scale_factor_x, scale_factor_y] \n",
        "\t\tbboxes\t= new_bbox\n",
        "\t\tbboxes = clip_box(bboxes, [0,0,w, h], 0.25)\n",
        "\t\treturn img, bboxes\n",
        "\n",
        "class RandomShear(object):\n",
        "\tdef __init__(self, shear_factor = 0.2):\n",
        "\t\tself.shear_factor = shear_factor\n",
        "\t\tif type(self.shear_factor) == tuple:\n",
        "\t\t\tassert len(self.shear_factor) == 2, \"Invalid range for scaling factor\"\t \n",
        "\t\telse:\n",
        "\t\t\tself.shear_factor = (-self.shear_factor, self.shear_factor)\n",
        "\t\tshear_factor = random.uniform(*self.shear_factor)\n",
        "\tdef __call__(self, img, bboxes):\n",
        "\t\tshear_factor = random.uniform(*self.shear_factor)\n",
        "\t\tw,h = img.shape[1], img.shape[0]\n",
        "\t\tif shear_factor < 0:\n",
        "\t\t\timg, bboxes = HorizontalFlip()(img, bboxes)\n",
        "\t\tM = np.array([[1, abs(shear_factor), 0],[0,1,0]])\n",
        "\t\tnW =  img.shape[1] + abs(shear_factor*img.shape[0])\n",
        "\t\tbboxes[:,[0,2]] += ((bboxes[:,[1,3]]) * abs(shear_factor) ).astype(int) \n",
        "\t\timg = cv2.warpAffine(img, M, (int(nW), img.shape[0]))\n",
        "\t\tif shear_factor < 0:\n",
        "\t\t\timg, bboxes = HorizontalFlip()(img, bboxes)\n",
        "\t\timg = cv2.resize(img, (w,h))\n",
        "\t\tscale_factor_x = nW / w\n",
        "\t\tbboxes[:,:4] /= [scale_factor_x, 1, scale_factor_x, 1] \n",
        "\t\treturn img, bboxes\n",
        "\t\t\n",
        "class Shear(object):\n",
        "\tdef __init__(self, shear_factor = 0.2):\n",
        "\t\tself.shear_factor = shear_factor\n",
        "\tdef __call__(self, img, bboxes):\n",
        "\t\tshear_factor = self.shear_factor\n",
        "\t\tif shear_factor < 0:\n",
        "\t\t\timg, bboxes = HorizontalFlip()(img, bboxes)\n",
        "\t\tM = np.array([[1, abs(shear_factor), 0],[0,1,0]])\n",
        "\t\tnW =  img.shape[1] + abs(shear_factor*img.shape[0])\n",
        "\t\tbboxes[:,[0,2]] += ((bboxes[:,[1,3]])*abs(shear_factor)).astype(int) \n",
        "\t\timg = cv2.warpAffine(img, M, (int(nW), img.shape[0]))\n",
        "\t\tif shear_factor < 0:\n",
        "\t\t\t img, bboxes = HorizontalFlip()(img, bboxes)\n",
        "\t\treturn img, bboxes\n",
        "\t\n",
        "class Resize(object):\n",
        "\tdef __init__(self, inp_dim):\n",
        "\t\tself.inp_dim = inp_dim\n",
        "\tdef __call__(self, img, bboxes):\n",
        "\t\tw,h = img.shape[1], img.shape[0]\n",
        "\t\timg = letterbox_image(img, self.inp_dim)\n",
        "\t\tscale = min(self.inp_dim/h, self.inp_dim/w)\n",
        "\t\tbboxes[:,:4] *= (scale)\n",
        "\t\tnew_w = scale*w\n",
        "\t\tnew_h = scale*h\n",
        "\t\tinp_dim = self.inp_dim\t \n",
        "\t\tdel_h = (inp_dim - new_h)/2\n",
        "\t\tdel_w = (inp_dim - new_w)/2\n",
        "\t\tadd_matrix = np.array([[del_w, del_h, del_w, del_h]]).astype(int)\n",
        "\t\tbboxes[:,:4] += add_matrix\n",
        "\t\timg = img.astype(np.uint8)\n",
        "\t\treturn img, bboxes \n",
        "\n",
        "class RandomHSV(object):\n",
        "\tdef __init__(self, hue = None, saturation = None, brightness = None):\n",
        "\t\tif hue:\n",
        "\t\t\tself.hue = hue \n",
        "\t\telse:\n",
        "\t\t\tself.hue = 0\n",
        "\t\tif saturation:\n",
        "\t\t\tself.saturation = saturation \n",
        "\t\telse:\n",
        "\t\t\tself.saturation = 0\n",
        "\t\tif brightness:\n",
        "\t\t\tself.brightness = brightness\n",
        "\t\telse:\n",
        "\t\t\tself.brightness = 0\n",
        "\t\tif type(self.hue) != tuple:\n",
        "\t\t\tself.hue = (-self.hue, self.hue)\n",
        "\t\tif type(self.saturation) != tuple:\n",
        "\t\t\tself.saturation = (-self.saturation, self.saturation)\n",
        "\t\tif type(brightness) != tuple:\n",
        "\t\t\tself.brightness = (-self.brightness, self.brightness)\n",
        "\tdef __call__(self, img, bboxes):\n",
        "\t\thue = random.randint(*self.hue)\n",
        "\t\tsaturation = random.randint(*self.saturation)\n",
        "\t\tbrightness = random.randint(*self.brightness)\n",
        "\t\timg = img.astype(int)\n",
        "\t\ta = np.array([hue, saturation, brightness]).astype(int)\n",
        "\t\timg += np.reshape(a, (1,1,3))\n",
        "\t\timg = np.clip(img, 0, 255)\n",
        "\t\timg[:,:,0] = np.clip(img[:,:,0],0, 179)\n",
        "\t\timg = img.astype(np.uint8)\n",
        "\t\treturn img, bboxes\n",
        "\t\n",
        "class Sequence(object):\n",
        "\tdef __init__(self, augmentations, probs = 1):\n",
        "\t\tself.augmentations = augmentations\n",
        "\t\tself.probs = probs\n",
        "\tdef __call__(self, images, bboxes):\n",
        "\t\tfor i, augmentation in enumerate(self.augmentations):\n",
        "\t\t\tif type(self.probs) == list:\n",
        "\t\t\t\tprob = self.probs[i]\n",
        "\t\t\telse:\n",
        "\t\t\t\tprob = self.probs\n",
        "\t\t\tif random.random() < prob:\n",
        "\t\t\t\timages, bboxes = augmentation(images, bboxes)\n",
        "\t\treturn images, bboxes\n",
        "\n",
        "def augment_bbox(image_input='./dataset/Ori',\n",
        "\t\t\t\timage_output='./dataset/Train',\n",
        "\t\t\t\tbbox_output='./dataset/Annotations',\n",
        "\t\t\t\tcount=3):\n",
        "\tTheLines = []\n",
        "\tBBOX = defaultdict(list)\n",
        "\twith open('object.csv', 'r') as F:\n",
        "\t\t#next(F)\n",
        "\t\tfor line in F:\n",
        "\t\t\tline = line.strip().split(':')\n",
        "\t\t\tfilename = line[0].split(',')[0]\n",
        "\t\t\tlabel = line[5].split('\"')[4]\n",
        "\t\t\tx = int(line[2].split(',')[0])\n",
        "\t\t\ty = int(line[3].split(',')[0])\n",
        "\t\t\tw = int(line[4].split(',')[0])\n",
        "\t\t\th = int(line[5].split(',')[0].split('}')[0])\n",
        "\t\t\tBBOX[filename].append([x, y, w, h, label])\n",
        "\tfor Images in os.listdir(image_input):\n",
        "\t\tIname = Images.split('.')[0]\n",
        "\t\tbboxes = np.array(BBOX[Images], dtype=object)\n",
        "\t\timg = cv2.imread('{}/{}'.format(image_input, Images))[:,:,::-1]\n",
        "\t\tfor i in range(count):\n",
        "\t\t\tseq = Sequence([\n",
        "\t\t\t\tRandomHorizontalFlip(0.5),\n",
        "\t\t\t\tRandomVerticalFlip(0.5),\n",
        "\t\t\t\tRandomRotate(15),\n",
        "\t\t\t\tRandomScale(0.01),\n",
        "\t\t\t\tRandomTranslate(0.1),\n",
        "\t\t\t\tRandomShear(0.1),\n",
        "\t\t\t\tRandomHSV(20, 20, 20)])\n",
        "\t\t\timg_, bboxes_ = seq(img.copy(), bboxes.copy())\n",
        "\t\t\tIoutput = '{}/Aug_{}-{}.jpg'.format(image_output, Iname, i+1)\n",
        "\t\t\tnew_image = array_to_img(img_, scale=True)\n",
        "\t\t\tnew_image.save(Ioutput)\n",
        "\t\t\tlist_of_boxes = np.ndarray.tolist(bboxes_)\n",
        "\t\t\tBoutput = '{}/Aug_{}-{}.xml'.format(bbox_output, Iname, i+1)\n",
        "\t\t\twith open(Boutput, 'w') as f:\n",
        "\t\t\t\tsource = 'https://github.com/sarisabban/SinfNet'\n",
        "\t\t\t\ttotal = bboxes_.shape[0]\n",
        "\t\t\t\tfilename = 'Aug_{}-{}'.format(Iname, i+1)\n",
        "\t\t\t\tW, H = Image.open('{}/{}'.format(image_input, Images)).size\n",
        "\t\t\t\tf.write('<annotation>\\n')\n",
        "\t\t\t\tf.write('\\t<filename>{}.jpg</filename>\\n'.format(filename))\n",
        "\t\t\t\tf.write('\\t<source>{}</source>\\n'.format(source))\n",
        "\t\t\t\tf.write('\\t<path>../dataset/Train/{}.jpg</path>\\n'.format(filename))\n",
        "\t\t\t\tf.write('\\t<size>\\n')\n",
        "\t\t\t\tf.write('\\t\\t<width>{}</width>\\n'.format(W))\n",
        "\t\t\t\tf.write('\\t\\t<height>{}</height>\\n'.format(H))\n",
        "\t\t\t\tf.write('\\t\\t<depth>3</depth>\\n')\n",
        "\t\t\t\tf.write('\\t</size>\\n')\n",
        "\t\t\t\tf.write('\\t<segments>{}</segments>\\n'.format(total))\n",
        "\t\t\t\titems = 0\n",
        "\t\t\t\tfor line in bboxes_:\n",
        "\t\t\t\t\tline = np.ndarray.tolist(line)\n",
        "\t\t\t\t\tline = [str(i) for i in line]\n",
        "\t\t\t\t\tx = line[0]\n",
        "\t\t\t\t\ty = line[1]\n",
        "\t\t\t\t\tw = line[2]\n",
        "\t\t\t\t\th = line[3]\n",
        "\t\t\t\t\tlabel = line[4]\n",
        "\t\t\t\t\titems += 1\n",
        "\t\t\t\t\tf.write('\\t<object>\\n')\n",
        "\t\t\t\t\tf.write('\\t\\t<name>{}</name>\\n'.format(label))\n",
        "\t\t\t\t\tf.write('\\t\\t<bndbox>\\n')\n",
        "\t\t\t\t\tf.write('\\t\\t\\t<xmin>{}</xmin>\\n'.format(x))\n",
        "\t\t\t\t\tf.write('\\t\\t\\t<ymin>{}</ymin>\\n'.format(y))\n",
        "\t\t\t\t\tf.write('\\t\\t\\t<xmax>{}</xmax>\\n'.format(w))\n",
        "\t\t\t\t\tf.write('\\t\\t\\t<ymax>{}</ymax>\\n'.format(h))\n",
        "\t\t\t\t\tf.write('\\t\\t</bndbox>\\n')\n",
        "\t\t\t\t\tf.write('\\t</object>\\n')\n",
        "\t\t\t\tf.write('</annotation>')\n",
        "\n",
        "augment_bbox(count=3)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6S_v3j1JvFz"
      },
      "source": [
        "# Object detection training (Yolov3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oZ8AB1P5WUk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26777921-86c1-4588-d691-646378ace908"
      },
      "source": [
        "#Runtime > Restart runtime\n",
        "%tensorflow_version 1.x \n",
        "\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import copy\n",
        "import json\n",
        "import scipy\n",
        "import keras\n",
        "import pickle\n",
        "import argparse\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import xml.etree.ElementTree as ET\n",
        "from keras.utils import Sequence\n",
        "from keras.optimizers import Adam\n",
        "from keras.engine.topology import Layer\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.layers import Lambda, concatenate, ZeroPadding2D, UpSampling2D, Lambda, Conv2D, Input, BatchNormalization, LeakyReLU\n",
        "\n",
        "config = {\"model\":{\n",
        "\t\t\t\"min_input_size\":       288,\n",
        "\t\t\t\"max_input_size\":       448,\n",
        "\t\t\t\"anchors\":              [55,69,75,234,133,240,136,129,142,363,203,290,228,184,285,359,341,260],\n",
        "\t\t\t\"labels\":               [\"Paramecium\"]},\n",
        "\t\t\"train\":{\n",
        "\t\t\t\"train_image_folder\":   \"./dataset/Train/\",\n",
        "\t\t\t\"train_annot_folder\":   \"./dataset/Annotations/\",\n",
        "\t\t\t\"tensorboard_dir\":      \"./logs\",\n",
        "\t\t\t\"saved_weights_name\":   \"./weights.h5\",\n",
        "\t\t\t\"cache_name\":           \"./training.pkl\",\n",
        "\t\t\t\"pretrained_weights\":   \"\",\n",
        "\t\t\t\"train_times\":          16,\n",
        "\t\t\t\"batch_size\":           8,\n",
        "\t\t\t\"learning_rate\":        1e-4,\n",
        "\t\t\t\"nb_epochs\":            100,\n",
        "\t\t\t\"warmup_epochs\":        0,\n",
        "\t\t\t\"ignore_thresh\":        0.5,\n",
        "\t\t\t\"gpus\":                 \"0,1\",\n",
        "\t\t\t\"grid_scales\":          [1,1,1],\n",
        "\t\t\t\"obj_scale\":            5,\n",
        "\t\t\t\"noobj_scale\":          1,\n",
        "\t\t\t\"xywh_scale\":           1,\n",
        "\t\t\t\"class_scale\":          1,\n",
        "\t\t\t\"debug\":                False},\n",
        "\t\t\"valid\":{\n",
        "\t\t\t\"valid_image_folder\":   \"./dataset/Valid/\",\n",
        "\t\t\t\"valid_annot_folder\":   \"./dataset/Valid_Annotations/\",\n",
        "\t\t\t\"cache_name\":           \"\",\n",
        "\t\t\t\"valid_times\":          1}}\n",
        "\n",
        "class YoloLayer(Layer):\n",
        "\tdef __init__(self, anchors, max_grid, batch_size, warmup_batches, ignore_thresh, grid_scale, obj_scale, noobj_scale, xywh_scale, class_scale, **kwargs):\n",
        "\t\tself.ignore_thresh  = ignore_thresh\n",
        "\t\tself.warmup_batches = warmup_batches\n",
        "\t\tself.anchors        = tf.constant(anchors, dtype='float', shape=[1,1,1,3,2])\n",
        "\t\tself.grid_scale     = grid_scale\n",
        "\t\tself.obj_scale      = obj_scale\n",
        "\t\tself.noobj_scale    = noobj_scale\n",
        "\t\tself.xywh_scale     = xywh_scale\n",
        "\t\tself.class_scale    = class_scale\n",
        "\t\tmax_grid_h, max_grid_w = max_grid\n",
        "\t\tcell_x = tf.to_float(tf.reshape(tf.tile(tf.range(max_grid_w), [max_grid_h]), (1, max_grid_h, max_grid_w, 1, 1)))\n",
        "\t\tcell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
        "\t\tself.cell_grid = tf.tile(tf.concat([cell_x,cell_y],-1), [batch_size, 1, 1, 3, 1])\n",
        "\t\tsuper(YoloLayer, self).__init__(**kwargs)\n",
        "\tdef build(self, input_shape):\n",
        "\t\tsuper(YoloLayer, self).build(input_shape)\n",
        "\tdef call(self, x):\n",
        "\t\tinput_image, y_pred, y_true, true_boxes = x\n",
        "\t\ty_pred = tf.reshape(y_pred, tf.concat([tf.shape(y_pred)[:3], tf.constant([3, -1])], axis=0))\n",
        "\t\tobject_mask     = tf.expand_dims(y_true[..., 4], 4)\n",
        "\t\tbatch_seen = tf.Variable(0.)\n",
        "\t\tgrid_h          = tf.shape(y_true)[1]\n",
        "\t\tgrid_w          = tf.shape(y_true)[2]\n",
        "\t\tgrid_factor     = tf.reshape(tf.cast([grid_w, grid_h], tf.float32), [1,1,1,1,2])\n",
        "\t\tnet_h           = tf.shape(input_image)[1]\n",
        "\t\tnet_w           = tf.shape(input_image)[2]\n",
        "\t\tnet_factor      = tf.reshape(tf.cast([net_w, net_h], tf.float32), [1,1,1,1,2])\n",
        "\t\tpred_box_xy     = (self.cell_grid[:,:grid_h,:grid_w,:,:] + tf.sigmoid(y_pred[..., :2]))\n",
        "\t\tpred_box_wh     = y_pred[..., 2:4]\n",
        "\t\tpred_box_conf   = tf.expand_dims(tf.sigmoid(y_pred[..., 4]), 4)\n",
        "\t\tpred_box_class  = y_pred[..., 5:]\n",
        "\t\ttrue_box_xy     = y_true[..., 0:2]\n",
        "\t\ttrue_box_wh     = y_true[..., 2:4]\n",
        "\t\ttrue_box_conf   = tf.expand_dims(y_true[..., 4], 4)\n",
        "\t\ttrue_box_class  = tf.argmax(y_true[..., 5:], -1)\n",
        "\t\tconf_delta      = pred_box_conf - 0\n",
        "\t\ttrue_xy         = true_boxes[..., 0:2] / grid_factor\n",
        "\t\ttrue_wh         = true_boxes[..., 2:4] / net_factor\n",
        "\t\ttrue_wh_half    = true_wh / 2.\n",
        "\t\ttrue_mins       = true_xy - true_wh_half\n",
        "\t\ttrue_maxes      = true_xy + true_wh_half\n",
        "\t\tpred_xy         = tf.expand_dims(pred_box_xy / grid_factor, 4)\n",
        "\t\tpred_wh         = tf.expand_dims(tf.exp(pred_box_wh) * self.anchors / net_factor, 4)\n",
        "\t\tpred_wh_half    = pred_wh / 2.\n",
        "\t\tpred_mins       = pred_xy - pred_wh_half\n",
        "\t\tpred_maxes      = pred_xy + pred_wh_half\n",
        "\t\tintersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "\t\tintersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "\t\tintersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "\t\tintersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "\t\ttrue_areas      = true_wh[..., 0] * true_wh[..., 1]\n",
        "\t\tpred_areas      = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "\t\tunion_areas     = pred_areas + true_areas - intersect_areas\n",
        "\t\tiou_scores      = tf.truediv(intersect_areas, union_areas)\n",
        "\t\tbest_ious       = tf.reduce_max(iou_scores, axis=4)\n",
        "\t\tconf_delta     *= tf.expand_dims(tf.to_float(best_ious < self.ignore_thresh), 4)\n",
        "\t\ttrue_xy         = true_box_xy / grid_factor\n",
        "\t\ttrue_wh         = tf.exp(true_box_wh) * self.anchors / net_factor\n",
        "\t\ttrue_wh_half    = true_wh / 2.\n",
        "\t\ttrue_mins       = true_xy - true_wh_half\n",
        "\t\ttrue_maxes      = true_xy + true_wh_half\n",
        "\t\tpred_xy         = pred_box_xy / grid_factor\n",
        "\t\tpred_wh         = tf.exp(pred_box_wh) * self.anchors / net_factor\n",
        "\t\tpred_wh_half    = pred_wh / 2.\n",
        "\t\tpred_mins       = pred_xy - pred_wh_half\n",
        "\t\tpred_maxes      = pred_xy + pred_wh_half\n",
        "\t\tintersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "\t\tintersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "\t\tintersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "\t\tintersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "\t\ttrue_areas      = true_wh[..., 0] * true_wh[..., 1]\n",
        "\t\tpred_areas      = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "\t\tunion_areas     = pred_areas + true_areas - intersect_areas\n",
        "\t\tiou_scores      = tf.truediv(intersect_areas, union_areas)\n",
        "\t\tiou_scores      = object_mask * tf.expand_dims(iou_scores, 4)\n",
        "\t\tcount           = tf.reduce_sum(object_mask)\n",
        "\t\tcount_noobj     = tf.reduce_sum(1 - object_mask)\n",
        "\t\tdetect_mask     = tf.to_float((pred_box_conf*object_mask) >= 0.5)\n",
        "\t\tclass_mask      = tf.expand_dims(tf.to_float(tf.equal(tf.argmax(pred_box_class, -1), true_box_class)), 4)\n",
        "\t\trecall50        = tf.reduce_sum(tf.to_float(iou_scores >= 0.5 ) * detect_mask  * class_mask) / (count + 1e-3)\n",
        "\t\trecall75        = tf.reduce_sum(tf.to_float(iou_scores >= 0.75) * detect_mask  * class_mask) / (count + 1e-3)\n",
        "\t\tavg_iou         = tf.reduce_sum(iou_scores) / (count + 1e-3)\n",
        "\t\tavg_obj         = tf.reduce_sum(pred_box_conf  * object_mask)  / (count + 1e-3)\n",
        "\t\tavg_noobj       = tf.reduce_sum(pred_box_conf  * (1-object_mask))  / (count_noobj + 1e-3)\n",
        "\t\tavg_cat         = tf.reduce_sum(object_mask * class_mask) / (count + 1e-3)\n",
        "\t\tbatch_seen      = tf.assign_add(batch_seen, 1.)\n",
        "\t\ttrue_box_xy, true_box_wh, xywh_mask = tf.cond(tf.less(batch_seen, self.warmup_batches+1), lambda: [true_box_xy + (0.5 + self.cell_grid[:,:grid_h,:grid_w,:,:]) * (1-object_mask), true_box_wh + tf.zeros_like(true_box_wh) * (1-object_mask), tf.ones_like(object_mask)], lambda: [true_box_xy, true_box_wh, object_mask])\n",
        "\t\twh_scale        = tf.exp(true_box_wh) * self.anchors / net_factor\n",
        "\t\twh_scale        = tf.expand_dims(2 - wh_scale[..., 0] * wh_scale[..., 1], axis=4)\n",
        "\t\txy_delta        = xywh_mask     * (pred_box_xy-true_box_xy) * wh_scale * self.xywh_scale\n",
        "\t\twh_delta        = xywh_mask     * (pred_box_wh-true_box_wh) * wh_scale * self.xywh_scale\n",
        "\t\tconf_delta      = object_mask   * (pred_box_conf-true_box_conf) * self.obj_scale + (1-object_mask) * conf_delta * self.noobj_scale\n",
        "\t\tclass_delta     = object_mask   * tf.expand_dims(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class), 4) * self.class_scale\n",
        "\t\tloss_xy         = tf.reduce_sum(tf.square(xy_delta),        list(range(1,5)))\n",
        "\t\tloss_wh         = tf.reduce_sum(tf.square(wh_delta),        list(range(1,5)))\n",
        "\t\tloss_conf       = tf.reduce_sum(tf.square(conf_delta),      list(range(1,5)))\n",
        "\t\tloss_class      = tf.reduce_sum(class_delta,                list(range(1,5)))\n",
        "\t\tloss            = loss_xy + loss_wh + loss_conf + loss_class\n",
        "\t\tif config['train']['debug']:\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, avg_obj], message='avg_obj \\t\\t', summarize=1000)\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, avg_noobj], message='avg_noobj \\t\\t', summarize=1000)\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, avg_iou], message='avg_iou \\t\\t', summarize=1000)\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, avg_cat], message='avg_cat \\t\\t', summarize=1000)\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, recall50], message='recall50 \\t', summarize=1000)\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, recall75], message='recall75 \\t', summarize=1000)\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, count], message='count \\t', summarize=1000)\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, tf.reduce_sum(loss_xy), tf.reduce_sum(loss_wh), tf.reduce_sum(loss_conf), tf.reduce_sum(loss_class)], message='loss xy, wh, conf, class: \\t', summarize=1000)\n",
        "\t\treturn loss*self.grid_scale\n",
        "\tdef compute_output_shape(self, input_shape):\n",
        "\t\treturn [(None, 1)]\n",
        "\n",
        "def _rand_scale(scale):\n",
        "\tscale = np.random.uniform(1, scale)\n",
        "\treturn scale if (np.random.randint(2) == 0) else 1./scale;\n",
        "\n",
        "def _constrain(min_v, max_v, value):\n",
        "\tif value < min_v: return min_v\n",
        "\tif value > max_v: return max_v\n",
        "\treturn value\n",
        "\n",
        "def random_flip(image, flip):\n",
        "\tif flip == 1: return cv2.flip(image, 1)\n",
        "\treturn image\n",
        "\n",
        "def correct_bounding_boxes(boxes, new_w, new_h, net_w, net_h, dx, dy, flip, image_w, image_h):\n",
        "\tboxes = copy.deepcopy(boxes)\n",
        "\tnp.random.shuffle(boxes)\n",
        "\tsx, sy = float(new_w)/image_w, float(new_h)/image_h\n",
        "\tzero_boxes = []\n",
        "\tfor i in range(len(boxes)):\n",
        "\t\tboxes[i]['xmin'] = int(_constrain(0, net_w, boxes[i]['xmin']*sx + dx))\n",
        "\t\tboxes[i]['xmax'] = int(_constrain(0, net_w, boxes[i]['xmax']*sx + dx))\n",
        "\t\tboxes[i]['ymin'] = int(_constrain(0, net_h, boxes[i]['ymin']*sy + dy))\n",
        "\t\tboxes[i]['ymax'] = int(_constrain(0, net_h, boxes[i]['ymax']*sy + dy))\n",
        "\t\tif boxes[i]['xmax'] <= boxes[i]['xmin'] or boxes[i]['ymax'] <= boxes[i]['ymin']:\n",
        "\t\t\tzero_boxes += [i]\n",
        "\t\t\tcontinue\n",
        "\t\tif flip == 1:\n",
        "\t\t\tswap = boxes[i]['xmin'];\n",
        "\t\t\tboxes[i]['xmin'] = net_w - boxes[i]['xmax']\n",
        "\t\t\tboxes[i]['xmax'] = net_w - swap\n",
        "\tboxes = [boxes[i] for i in range(len(boxes)) if i not in zero_boxes]\n",
        "\treturn boxes\n",
        "\n",
        "def random_distort_image(image, hue=18, saturation=1.5, exposure=1.5):\n",
        "\tdhue = np.random.uniform(-hue, hue)\n",
        "\tdsat = _rand_scale(saturation);\n",
        "\tdexp = _rand_scale(exposure);\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype('float')\n",
        "\timage[:,:,1] *= dsat\n",
        "\timage[:,:,2] *= dexp\n",
        "\timage[:,:,0] += dhue\n",
        "\timage[:,:,0] -= (image[:,:,0] > 180)*180\n",
        "\timage[:,:,0] += (image[:,:,0] < 0)  *180\n",
        "\treturn cv2.cvtColor(image.astype('uint8'), cv2.COLOR_HSV2RGB)\n",
        "\n",
        "def apply_random_scale_and_crop(image, new_w, new_h, net_w, net_h, dx, dy):\n",
        "\tim_sized = cv2.resize(image, (new_w, new_h))\n",
        "\tif dx > 0:\n",
        "\t\tim_sized = np.pad(im_sized, ((0,0), (dx,0), (0,0)), mode='constant', constant_values=127)\n",
        "\telse:\n",
        "\t\tim_sized = im_sized[:,-dx:,:]\n",
        "\tif (new_w + dx) < net_w:\n",
        "\t\tim_sized = np.pad(im_sized, ((0,0), (0, net_w - (new_w+dx)), (0,0)), mode='constant', constant_values=127)\n",
        "\tif dy > 0:\n",
        "\t\tim_sized = np.pad(im_sized, ((dy,0), (0,0), (0,0)), mode='constant', constant_values=127)\n",
        "\telse:\n",
        "\t\tim_sized = im_sized[-dy:,:,:]\n",
        "\tif (new_h + dy) < net_h:\n",
        "\t\tim_sized = np.pad(im_sized, ((0, net_h - (new_h+dy)), (0,0), (0,0)), mode='constant', constant_values=127)\n",
        "\treturn im_sized[:net_h, :net_w,:]\n",
        "\n",
        "def _conv_block(inp, convs, do_skip=True):\n",
        "\tx = inp\n",
        "\tcount = 0\n",
        "\tfor conv in convs:\n",
        "\t\tif count == (len(convs) - 2) and do_skip:\n",
        "\t\t\tskip_connection = x\n",
        "\t\tcount += 1\n",
        "\t\tif conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x)\n",
        "\t\tx = Conv2D(conv['filter'],\n",
        "\t\t\t\t\tconv['kernel'],\n",
        "\t\t\t\t\tstrides=conv['stride'],\n",
        "\t\t\t\t\tpadding='valid' if conv['stride'] > 1 else 'same',\n",
        "\t\t\t\t\tname='conv_' + str(conv['layer_idx']),\n",
        "\t\t\t\t\tuse_bias=False if conv['bnorm'] else True)(x)\n",
        "\t\tif conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "\t\tif conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "\treturn add([skip_connection, x]) if do_skip else x\n",
        "\n",
        "def create_yolov3_model(nb_class, anchors, max_box_per_image, max_grid, batch_size, warmup_batches, ignore_thresh, grid_scales, obj_scale, noobj_scale, xywh_scale, class_scale):\n",
        "\tinput_image     = Input(shape=(None, None, 3))\n",
        "\ttrue_boxes      = Input(shape=(1, 1, 1, max_box_per_image, 4))\n",
        "\ttrue_yolo_1     = Input(shape=(None, None, len(anchors)//6, 4+1+nb_class))\n",
        "\ttrue_yolo_2     = Input(shape=(None, None, len(anchors)//6, 4+1+nb_class))\n",
        "\ttrue_yolo_3     = Input(shape=(None, None, len(anchors)//6, 4+1+nb_class))\n",
        "\tx = _conv_block(input_image, [\t{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "\tx = _conv_block(x, [\t\t\t{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "\t\t\t\t\t\t\t\t\t{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "\tx = _conv_block(x, [\t\t\t{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "\tx = _conv_block(x, [\t\t\t{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "\tfor i in range(7):\n",
        "\t\tx = _conv_block(x, [\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "\tskip_36 = x\n",
        "\tx = _conv_block(x, [\t\t\t{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "\tfor i in range(7):\n",
        "\t\tx = _conv_block(x, [\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "\tskip_61 = x\n",
        "\tx = _conv_block(x, [\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "\t\t\t\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "\tfor i in range(3):\n",
        "\t\tx = _conv_block(x, [\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "\tx = _conv_block(x, [\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "\t\t\t\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "\t\t\t\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], do_skip=False)\n",
        "\tpred_yolo_1 = _conv_block(x, [\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': (3*(5+nb_class)), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], do_skip=False)\n",
        "\tloss_yolo_1 = YoloLayer(anchors[12:], [1*num for num in max_grid], batch_size, warmup_batches, ignore_thresh, grid_scales[0], obj_scale, noobj_scale, xywh_scale, class_scale)([input_image, pred_yolo_1, true_yolo_1, true_boxes])\n",
        "\tx = _conv_block(x, [\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], do_skip=False)\n",
        "\tx = UpSampling2D(2)(x)\n",
        "\tx = concatenate([x, skip_61])\n",
        "\tx = _conv_block(x, [\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], do_skip=False)\n",
        "\tpred_yolo_2 = _conv_block(x, [\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': (3*(5+nb_class)), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], do_skip=False)\n",
        "\tloss_yolo_2 = YoloLayer(anchors[6:12], [2*num for num in max_grid], batch_size, warmup_batches, ignore_thresh, grid_scales[1], obj_scale, noobj_scale, xywh_scale, class_scale)([input_image, pred_yolo_2, true_yolo_2, true_boxes])\n",
        "\tx = _conv_block(x, [\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], do_skip=False)\n",
        "\tx = UpSampling2D(2)(x)\n",
        "\tx = concatenate([x, skip_36])\n",
        "\tpred_yolo_3 = _conv_block(x, [\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': (3*(5+nb_class)), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], do_skip=False)\n",
        "\tloss_yolo_3 = YoloLayer(anchors[:6], [4*num for num in max_grid], batch_size, warmup_batches, ignore_thresh, grid_scales[2], obj_scale, noobj_scale, xywh_scale, class_scale)([input_image, pred_yolo_3, true_yolo_3, true_boxes])\n",
        "\ttrain_model = Model([input_image, true_boxes, true_yolo_1, true_yolo_2, true_yolo_3], [loss_yolo_1, loss_yolo_2, loss_yolo_3])\n",
        "\tinfer_model = Model(input_image, [pred_yolo_1, pred_yolo_2, pred_yolo_3])\n",
        "\treturn [train_model, infer_model]\n",
        "\n",
        "def dummy_loss(y_true, y_pred):\n",
        "\treturn tf.sqrt(tf.reduce_sum(y_pred))\n",
        "\n",
        "def multi_gpu_model(model, gpus):\n",
        "\tif isinstance(gpus, (list, tuple)):\n",
        "\t\tnum_gpus = len(gpus)\n",
        "\t\ttarget_gpu_ids = gpus\n",
        "\telse:\n",
        "\t\tnum_gpus = gpus\n",
        "\t\ttarget_gpu_ids = range(num_gpus)\n",
        "\tdef get_slice(data, i, parts):\n",
        "\t\tshape = tf.shape(data)\n",
        "\t\tbatch_size = shape[:1]\n",
        "\t\tinput_shape = shape[1:]\n",
        "\t\tstep = batch_size // parts\n",
        "\t\tif i == num_gpus - 1:\n",
        "\t\t\tsize = batch_size - step * i\n",
        "\t\telse:\n",
        "\t\t\tsize = step\n",
        "\t\tsize = tf.concat([size, input_shape], axis=0)\n",
        "\t\tstride = tf.concat([step, input_shape * 0], axis=0)\n",
        "\t\tstart = stride * i\n",
        "\t\treturn tf.slice(data, start, size)\n",
        "\tall_outputs = []\n",
        "\tfor i in range(len(model.outputs)):\n",
        "\t\tall_outputs.append([])\n",
        "\tfor i, gpu_id in enumerate(target_gpu_ids):\n",
        "\t\twith tf.device('/gpu:%d' % gpu_id):\n",
        "\t\t\twith tf.name_scope('replica_%d' % gpu_id):\n",
        "\t\t\t\tinputs = []\n",
        "\t\t\t\tfor x in model.inputs:\n",
        "\t\t\t\t\tinput_shape = tuple(x.get_shape().as_list())[1:]\n",
        "\t\t\t\t\tslice_i = Lambda(get_slice, output_shape=input_shape, arguments={'i': i, 'parts': num_gpus})(x)\n",
        "\t\t\t\t\tinputs.append(slice_i)\n",
        "\t\t\t\toutputs = model(inputs)\n",
        "\t\t\t\tif not isinstance(outputs, list):\n",
        "\t\t\t\t\toutputs = [outputs]\n",
        "\t\t\t\tfor o in range(len(outputs)):\n",
        "\t\t\t\t\tall_outputs[o].append(outputs[o])\n",
        "\twith tf.device('/cpu:0'):\n",
        "\t\tmerged = []\n",
        "\t\tfor name, outputs in zip(model.output_names, all_outputs):\n",
        "\t\t\tmerged.append(concatenate(outputs, axis=0, name=name))\n",
        "\t\treturn Model(model.inputs, merged)\n",
        "\n",
        "def get_color(label):\n",
        "\tif label < len(colors):\n",
        "\t\treturn colors[label]\n",
        "\telse:\n",
        "\t\tprint('Label {} has no color, returning default.'.format(label))\n",
        "\t\treturn (0, 255, 0)\n",
        "\n",
        "colors = \t[[31 , 0   , 255] ,\n",
        "\t\t\t[0   , 159 , 255] ,\n",
        "\t\t\t[255 , 95  , 0]   ,\n",
        "\t\t\t[255 , 19  , 0]   ,\n",
        "\t\t\t[255 , 0   , 0]   ,\n",
        "\t\t\t[255 , 38  , 0]   ,\n",
        "\t\t\t[0   , 255 , 25]  ,\n",
        "\t\t\t[255 , 0   , 133] ,\n",
        "\t\t\t[255 , 172 , 0]   ,\n",
        "\t\t\t[108 , 0   , 255] ,\n",
        "\t\t\t[0   , 82  , 255] ,\n",
        "\t\t\t[0   , 255 , 6]   ,\n",
        "\t\t\t[255 , 0   , 152] ,\n",
        "\t\t\t[223 , 0   , 255] ,\n",
        "\t\t\t[12  , 0   , 255] ,\n",
        "\t\t\t[0   , 255 , 178] ,\n",
        "\t\t\t[108 , 255 , 0]   ,\n",
        "\t\t\t[184 , 0   , 255] ,\n",
        "\t\t\t[255 , 0   , 76]  ,\n",
        "\t\t\t[146 , 255 , 0]   ,\n",
        "\t\t\t[51  , 0   , 255] ,\n",
        "\t\t\t[0   , 197 , 255] ,\n",
        "\t\t\t[255 , 248 , 0]   ,\n",
        "\t\t\t[255 , 0   , 19]  ,\n",
        "\t\t\t[255 , 0   , 38]  ,\n",
        "\t\t\t[89  , 255 , 0]   ,\n",
        "\t\t\t[127 , 255 , 0]   ,\n",
        "\t\t\t[255 , 153 , 0]   ,\n",
        "\t\t\t[0   , 255 , 255] ,\n",
        "\t\t\t[0   , 255 , 216] ,\n",
        "\t\t\t[0   , 255 , 121] ,\n",
        "\t\t\t[255 , 0   , 248] ,\n",
        "\t\t\t[70  , 0   , 255] ,\n",
        "\t\t\t[0   , 255 , 159] ,\n",
        "\t\t\t[0   , 216 , 255] ,\n",
        "\t\t\t[0   , 6   , 255] ,\n",
        "\t\t\t[0   , 63  , 255] ,\n",
        "\t\t\t[31  , 255 , 0]   ,\n",
        "\t\t\t[255 , 57  , 0]   ,\n",
        "\t\t\t[255 , 0   , 210] ,\n",
        "\t\t\t[0   , 255 , 102] ,\n",
        "\t\t\t[242 , 255 , 0]   ,\n",
        "\t\t\t[255 , 191 , 0]   ,\n",
        "\t\t\t[0   , 255 , 63]  ,\n",
        "\t\t\t[255 , 0   , 95]  ,\n",
        "\t\t\t[146 , 0   , 255] ,\n",
        "\t\t\t[184 , 255 , 0]   ,\n",
        "\t\t\t[255 , 114 , 0]   ,\n",
        "\t\t\t[0   , 255 , 235] ,\n",
        "\t\t\t[255 , 229 , 0]   ,\n",
        "\t\t\t[0   , 178 , 255] ,\n",
        "\t\t\t[255 , 0   , 114] ,\n",
        "\t\t\t[255 , 0   , 57]  ,\n",
        "\t\t\t[0   , 140 , 255] ,\n",
        "\t\t\t[0   , 121 , 255] ,\n",
        "\t\t\t[12  , 255 , 0]   ,\n",
        "\t\t\t[255 , 210 , 0]   ,\n",
        "\t\t\t[0   , 255 , 44]  ,\n",
        "\t\t\t[165 , 255 , 0]   ,\n",
        "\t\t\t[0   , 25  , 255] ,\n",
        "\t\t\t[0   , 255 , 140] ,\n",
        "\t\t\t[0   , 101 , 255] ,\n",
        "\t\t\t[0   , 255 , 82]  ,\n",
        "\t\t\t[223 , 255 , 0]   ,\n",
        "\t\t\t[242 , 0   , 255] ,\n",
        "\t\t\t[89  , 0   , 255] ,\n",
        "\t\t\t[165 , 0   , 255] ,\n",
        "\t\t\t[70  , 255 , 0]   ,\n",
        "\t\t\t[255 , 0   , 172] ,\n",
        "\t\t\t[255 , 76  , 0]   ,\n",
        "\t\t\t[203 , 255 , 0]   ,\n",
        "\t\t\t[204 , 0   , 255] ,\n",
        "\t\t\t[255 , 0   , 229] ,\n",
        "\t\t\t[255 , 133 , 0]   ,\n",
        "\t\t\t[127 , 0   , 255] ,\n",
        "\t\t\t[0   , 235 , 255] ,\n",
        "\t\t\t[0   , 255 , 197] ,\n",
        "\t\t\t[255 , 0   , 191] ,\n",
        "\t\t\t[0   , 44  , 255] ,\n",
        "\t\t\t[50  , 255 , 0]]\n",
        "\n",
        "class BoundBox:\n",
        "\tdef __init__(self, xmin, ymin, xmax, ymax, c = None, classes = None):\n",
        "\t\tself.xmin = xmin\n",
        "\t\tself.ymin = ymin\n",
        "\t\tself.xmax = xmax\n",
        "\t\tself.ymax = ymax\n",
        "\t\tself.c    = c\n",
        "\t\tself.classes = classes\n",
        "\t\tself.label = -1\n",
        "\t\tself.score = -1\n",
        "\tdef get_label(self):\n",
        "\t\tif self.label == -1:\n",
        "\t\t\tself.label = np.argmax(self.classes)\n",
        "\t\tprint(self.xmin, self.ymin, self.xmax, self.ymax, config['model']['labels'][self.label])\n",
        "\t\treturn self.label\n",
        "\tdef get_score(self):\n",
        "\t\tif self.score == -1:\n",
        "\t\t\tself.score = self.classes[self.get_label()]\n",
        "\t\treturn self.score\n",
        "\n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "\tx1, x2 = interval_a\n",
        "\tx3, x4 = interval_b\n",
        "\tif x3 < x1:\n",
        "\t\tif x4 < x1: return 0\n",
        "\t\telse: return min(x2,x4) - x1\n",
        "\telse:\n",
        "\t\tif x2 < x3: return 0\n",
        "\t\telse: return min(x2,x4) - x3\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "\tintersect = intersect_w * intersect_h\n",
        "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\tunion = w1*h1 + w2*h2 - intersect\n",
        "\treturn float(intersect) / union\n",
        "\n",
        "def draw_boxes(image, boxes, labels, obj_thresh, quiet=True):\n",
        "\tfor box in boxes:\n",
        "\t\tlabel_str = ''\n",
        "\t\tlabel = -1\n",
        "\t\tfor i in range(len(labels)):\n",
        "\t\t\tif box.classes[i] > obj_thresh:\n",
        "\t\t\t\tif label_str != '': label_str += ', '\n",
        "\t\t\t\tlabel_str += (labels[i] + ' ' + str(round(box.get_score()*100, 2)) + '%')\n",
        "\t\t\t\tlabel = i\n",
        "\t\t\tif not quiet: print(label_str)\n",
        "\t\tif label >= 0:\n",
        "\t\t\ttext_size = cv2.getTextSize(label_str, cv2.FONT_HERSHEY_SIMPLEX, 1.1e-3 * image.shape[0], 5)\n",
        "\t\t\twidth, height = text_size[0][0], text_size[0][1]\n",
        "\t\t\tregion = np.array([[box.xmin-3, box.ymin], [box.xmin-3, box.ymin-height-26], [box.xmin+width+13, box.ymin-height-26], [box.xmin+width+13, box.ymin]], dtype='int32')\n",
        "\t\t\tcv2.rectangle(img=image, pt1=(box.xmin,box.ymin), pt2=(box.xmax,box.ymax), color=get_color(label), thickness=3)\n",
        "\t\t\tcv2.fillPoly(img=image, pts=[region], color=get_color(label))\n",
        "\t\t\tcv2.putText(img=image, text=label_str, org=(box.xmin+13, box.ymin - 13), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1e-3 * image.shape[0], color=(0,0,0), thickness=2)\n",
        "\treturn image\n",
        "\n",
        "def _sigmoid(x):\n",
        "\treturn scipy.special.expit(x)\n",
        " \n",
        "def makedirs(path):\n",
        "\ttry:\n",
        "\t\tos.makedirs(path)\n",
        "\texcept OSError:\n",
        "\t\tif not os.path.isdir(path):\n",
        "\t\t\traise\n",
        "\n",
        "def evaluate(model, generator, iou_threshold=0.5, obj_thresh=0.5, nms_thresh=0.45, net_h=416, net_w=416, save_path=None):\n",
        "\tall_detections      = [[None for i in range(generator.num_classes())] for j in range(generator.size())]\n",
        "\tall_annotations     = [[None for i in range(generator.num_classes())] for j in range(generator.size())]\n",
        "\tfor i in range(generator.size()):\n",
        "\t\traw_image = [generator.load_image(i)]\n",
        "\t\tpred_boxes = get_yolo_boxes(model, raw_image, net_h, net_w, generator.get_anchors(), obj_thresh, nms_thresh)[0]\n",
        "\t\tscore = np.array([box.get_score() for box in pred_boxes])\n",
        "\t\tpred_labels = np.array([box.label for box in pred_boxes])\n",
        "\t\tif len(pred_boxes) > 0:\n",
        "\t\t\tpred_boxes = np.array([[box.xmin, box.ymin, box.xmax, box.ymax, box.get_score()] for box in pred_boxes]) \n",
        "\t\telse:\n",
        "\t\t\tpred_boxes = np.array([[]])\n",
        "\t\tscore_sort  = np.argsort(-score)\n",
        "\t\tpred_labels = pred_labels[score_sort]\n",
        "\t\tpred_boxes  = pred_boxes[score_sort]\n",
        "\t\tfor label in range(generator.num_classes()):\n",
        "\t\t\tall_detections[i][label] = pred_boxes[pred_labels == label, :]\n",
        "\t\tannotations = generator.load_annotation(i)\n",
        "\t\tfor label in range(generator.num_classes()):\n",
        "\t\t\tall_annotations[i][label] = annotations[annotations[:, 4] == label, :4].copy()\n",
        "\taverage_precisions = {}\n",
        "\tfor label in range(generator.num_classes()):\n",
        "\t\tfalse_positives = np.zeros((0,))\n",
        "\t\ttrue_positives  = np.zeros((0,))\n",
        "\t\tscores          = np.zeros((0,))\n",
        "\t\tnum_annotations = 0.0\n",
        "\t\tfor i in range(generator.size()):\n",
        "\t\t\tdetections              = all_detections[i][label]\n",
        "\t\t\tannotations             = all_annotations[i][label]\n",
        "\t\t\tnum_annotations        += annotations.shape[0]\n",
        "\t\t\tdetected_annotations    = []\n",
        "\t\t\tfor d in detections:\n",
        "\t\t\t\tscores = np.append(scores, d[4])\n",
        "\t\t\t\tif annotations.shape[0] == 0:\n",
        "\t\t\t\t\tfalse_positives = np.append(false_positives, 1)\n",
        "\t\t\t\t\ttrue_positives  = np.append(true_positives, 0)\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\toverlaps            = compute_overlap(np.expand_dims(d, axis=0), annotations)\n",
        "\t\t\t\tassigned_annotation = np.argmax(overlaps, axis=1)\n",
        "\t\t\t\tmax_overlap         = overlaps[0, assigned_annotation]\n",
        "\t\t\t\tif max_overlap >= iou_threshold and assigned_annotation not in detected_annotations:\n",
        "\t\t\t\t\tfalse_positives = np.append(false_positives, 0)\n",
        "\t\t\t\t\ttrue_positives  = np.append(true_positives, 1)\n",
        "\t\t\t\t\tdetected_annotations.append(assigned_annotation)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tfalse_positives = np.append(false_positives, 1)\n",
        "\t\t\t\t\ttrue_positives  = np.append(true_positives, 0)\n",
        "\t\tif num_annotations == 0:\n",
        "\t\t\taverage_precisions[label] = 0\n",
        "\t\t\tcontinue\n",
        "\t\tindices         = np.argsort(-scores)\n",
        "\t\tfalse_positives = false_positives[indices]\n",
        "\t\ttrue_positives  = true_positives[indices]\n",
        "\t\tfalse_positives = np.cumsum(false_positives)\n",
        "\t\ttrue_positives  = np.cumsum(true_positives)\n",
        "\t\trecall          = true_positives / num_annotations\n",
        "\t\tprecision       = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
        "\t\taverage_precision           = compute_ap(recall, precision)\n",
        "\t\taverage_precisions[label]   = average_precision\n",
        "\treturn average_precisions\n",
        "\n",
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "\tif (float(net_w)/image_w) < (float(net_h)/image_h):\n",
        "\t\tnew_w = net_w\n",
        "\t\tnew_h = (image_h*net_w)/image_w\n",
        "\telse:\n",
        "\t\tnew_h = net_w\n",
        "\t\tnew_w = (image_w*net_h)/image_h\n",
        "\tfor i in range(len(boxes)):\n",
        "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
        "\n",
        "def do_nms(boxes, nms_thresh):\n",
        "\tif len(boxes) > 0:\n",
        "\t\tnb_class = len(boxes[0].classes)\n",
        "\telse:\n",
        "\t\treturn\n",
        "\tfor c in range(nb_class):\n",
        "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\t\tfor i in range(len(sorted_indices)):\n",
        "\t\t\tindex_i = sorted_indices[i]\n",
        "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
        "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
        "\t\t\t\tindex_j = sorted_indices[j]\n",
        "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "\t\t\t\t\tboxes[index_j].classes[c] = 0\n",
        "\n",
        "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
        "\tgrid_h, grid_w = netout.shape[:2]\n",
        "\tnb_box = 3\n",
        "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "\tnb_class = netout.shape[-1] - 5\n",
        "\tboxes = []\n",
        "\tnetout[..., :2]     = _sigmoid(netout[..., :2])\n",
        "\tnetout[..., 4]      = _sigmoid(netout[..., 4])\n",
        "\tnetout[..., 5:]     = netout[..., 4][..., np.newaxis] * _softmax(netout[..., 5:])\n",
        "\tnetout[..., 5:]    *= netout[..., 5:] > obj_thresh\n",
        "\tfor i in range(grid_h*grid_w):\n",
        "\t\trow = i // grid_w\n",
        "\t\tcol = i % grid_w\n",
        "\t\tfor b in range(nb_box):\n",
        "\t\t\tobjectness = netout[row, col, b, 4]\n",
        "\t\t\tif(objectness <= obj_thresh): continue\n",
        "\t\t\tx, y, w, h = netout[row,col,b,:4]\n",
        "\t\t\tx = (col + x) / grid_w\n",
        "\t\t\ty = (row + y) / grid_h\n",
        "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w\n",
        "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h\n",
        "\t\t\tclasses = netout[row,col,b,5:]\n",
        "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "\t\t\tboxes.append(box)\n",
        "\treturn boxes\n",
        "\n",
        "def preprocess_input(image, net_h, net_w):\n",
        "\tnew_h, new_w, _ = image.shape\n",
        "\tif (float(net_w)/new_w) < (float(net_h)/new_h):\n",
        "\t\tnew_h = (new_h * net_w)//new_w\n",
        "\t\tnew_w = net_w\n",
        "\telse:\n",
        "\t\tnew_w = (new_w * net_h)//new_h\n",
        "\t\tnew_h = net_h\n",
        "\tresized = cv2.resize(image[:,:,::-1]/255., (new_w, new_h))\n",
        "\tnew_image = np.ones((net_h, net_w, 3)) * 0.5\n",
        "\tnew_image[(net_h-new_h)//2:(net_h+new_h)//2, (net_w-new_w)//2:(net_w+new_w)//2, :] = resized\n",
        "\tnew_image = np.expand_dims(new_image, 0)\n",
        "\treturn new_image\n",
        "\n",
        "def normalize(image):\n",
        "\treturn image/255.\n",
        "\n",
        "def get_yolo_boxes(model, images, net_h, net_w, anchors, obj_thresh, nms_thresh):\n",
        "\timage_h, image_w, _ = images[0].shape\n",
        "\tnb_images           = len(images)\n",
        "\tbatch_input         = np.zeros((nb_images, net_h, net_w, 3))\n",
        "\tfor i in range(nb_images):\n",
        "\t\tbatch_input[i] = preprocess_input(images[i], net_h, net_w)\n",
        "\tbatch_output = model.predict_on_batch(batch_input)\n",
        "\tbatch_boxes  = [None]*nb_images\n",
        "\tfor i in range(nb_images):\n",
        "\t\tyolos = [batch_output[0][i], batch_output[1][i], batch_output[2][i]]\n",
        "\t\tboxes = []\n",
        "\t\tfor j in range(len(yolos)):\n",
        "\t\t\tyolo_anchors = anchors[(2-j)*6:(3-j)*6]\n",
        "\t\t\tboxes += decode_netout(yolos[j], yolo_anchors, obj_thresh, net_h, net_w)\n",
        "\t\tcorrect_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n",
        "\t\tdo_nms(boxes, nms_thresh)\n",
        "\t\tbatch_boxes[i] = boxes\n",
        "\treturn batch_boxes\n",
        "\n",
        "def compute_overlap(a, b):\n",
        "\tarea = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
        "\tiw = np.minimum(np.expand_dims(a[:, 2], axis=1), b[:, 2]) - np.maximum(np.expand_dims(a[:, 0], 1), b[:, 0])\n",
        "\tih = np.minimum(np.expand_dims(a[:, 3], axis=1), b[:, 3]) - np.maximum(np.expand_dims(a[:, 1], 1), b[:, 1])\n",
        "\tiw = np.maximum(iw, 0)\n",
        "\tih = np.maximum(ih, 0)\n",
        "\tua = np.expand_dims((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), axis=1) + area - iw * ih\n",
        "\tua = np.maximum(ua, np.finfo(float).eps)\n",
        "\tintersection = iw * ih\n",
        "\treturn intersection / ua\n",
        "\n",
        "def compute_ap(recall, precision):\n",
        "\tmrec = np.concatenate(([0.], recall, [1.]))\n",
        "\tmpre = np.concatenate(([0.], precision, [0.]))\n",
        "\tfor i in range(mpre.size - 1, 0, -1):\n",
        "\t\tmpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
        "\ti = np.where(mrec[1:] != mrec[:-1])[0]\n",
        "\tap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
        "\treturn ap\n",
        "\n",
        "def _softmax(x, axis=-1):\n",
        "\tx = x - np.amax(x, axis, keepdims=True)\n",
        "\te_x = np.exp(x)\n",
        "\treturn e_x / e_x.sum(axis, keepdims=True)\n",
        "\n",
        "class BatchGenerator(Sequence):\n",
        "\tdef __init__(self,\n",
        "\t\tinstances,\n",
        "\t\tanchors,\n",
        "\t\tlabels,\n",
        "\t\tdownsample=32,\n",
        "\t\tmax_box_per_image=30,\n",
        "\t\tbatch_size=1,\n",
        "\t\tmin_net_size=320,\n",
        "\t\tmax_net_size=608,\n",
        "\t\tshuffle=True,\n",
        "\t\tjitter=True,\n",
        "\t\tnorm=None):\n",
        "\t\tself.instances          = instances\n",
        "\t\tself.batch_size         = batch_size\n",
        "\t\tself.labels             = labels\n",
        "\t\tself.downsample         = downsample\n",
        "\t\tself.max_box_per_image  = max_box_per_image\n",
        "\t\tself.min_net_size       = (min_net_size // self.downsample) * self.downsample\n",
        "\t\tself.max_net_size       = (max_net_size // self.downsample) * self.downsample\n",
        "\t\tself.shuffle            = shuffle\n",
        "\t\tself.jitter             = jitter\n",
        "\t\tself.norm               = norm\n",
        "\t\tself.anchors            = [BoundBox(0, 0, anchors[2*i], anchors[2*i+1]) for i in range(len(anchors)//2)]\n",
        "\t\tself.net_h              = 416\n",
        "\t\tself.net_w              = 416\n",
        "\t\tif shuffle: np.random.shuffle(self.instances)\n",
        "\tdef __len__(self):\n",
        "\t\treturn int(np.ceil(float(len(self.instances))/self.batch_size))\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\tnet_h, net_w = self._get_net_size(idx)\n",
        "\t\tbase_grid_h, base_grid_w = net_h//self.downsample, net_w//self.downsample\n",
        "\t\tl_bound = idx*self.batch_size\n",
        "\t\tr_bound = (idx+1)*self.batch_size\n",
        "\t\tif r_bound > len(self.instances):\n",
        "\t\t\tr_bound = len(self.instances)\n",
        "\t\t\tl_bound = r_bound - self.batch_size\n",
        "\t\tx_batch = np.zeros((r_bound - l_bound, net_h, net_w, 3))\n",
        "\t\tt_batch = np.zeros((r_bound - l_bound, 1, 1, 1, self.max_box_per_image, 4))\n",
        "\t\tyolo_1 = np.zeros((r_bound - l_bound, 1*base_grid_h, 1*base_grid_w, len(self.anchors)//3, 4+1+len(self.labels)))\n",
        "\t\tyolo_2 = np.zeros((r_bound - l_bound, 2*base_grid_h, 2*base_grid_w, len(self.anchors)//3, 4+1+len(self.labels)))\n",
        "\t\tyolo_3 = np.zeros((r_bound - l_bound, 4*base_grid_h, 4*base_grid_w, len(self.anchors)//3, 4+1+len(self.labels)))\n",
        "\t\tyolos = [yolo_3, yolo_2, yolo_1]\n",
        "\t\tdummy_yolo_1 = np.zeros((r_bound - l_bound, 1))\n",
        "\t\tdummy_yolo_2 = np.zeros((r_bound - l_bound, 1))\n",
        "\t\tdummy_yolo_3 = np.zeros((r_bound - l_bound, 1))\n",
        "\t\tinstance_count = 0\n",
        "\t\ttrue_box_index = 0\n",
        "\t\tfor train_instance in self.instances[l_bound:r_bound]:\n",
        "\t\t\timg, all_objs = self._aug_image(train_instance, net_h, net_w)\n",
        "\t\t\tfor obj in all_objs:\n",
        "\t\t\t\tmax_anchor  = None\n",
        "\t\t\t\tmax_index   = -1\n",
        "\t\t\t\tmax_iou     = -1\n",
        "\t\t\t\tshifted_box = BoundBox(0, 0, obj['xmax']-obj['xmin'], obj['ymax']-obj['ymin'])\n",
        "\t\t\t\tfor i in range(len(self.anchors)):\n",
        "\t\t\t\t\tanchor  = self.anchors[i]\n",
        "\t\t\t\t\tiou     = bbox_iou(shifted_box, anchor)\n",
        "\t\t\t\t\tif max_iou < iou:\n",
        "\t\t\t\t\t\tmax_anchor  = anchor\n",
        "\t\t\t\t\t\tmax_index   = i\n",
        "\t\t\t\t\t\tmax_iou     = iou\n",
        "\t\t\t\tyolo = yolos[max_index//3]\n",
        "\t\t\t\tgrid_h, grid_w = yolo.shape[1:3]\n",
        "\t\t\t\tcenter_x = .5*(obj['xmin'] + obj['xmax'])\n",
        "\t\t\t\tcenter_x = center_x / float(net_w) * grid_w\n",
        "\t\t\t\tcenter_y = .5*(obj['ymin'] + obj['ymax'])\n",
        "\t\t\t\tcenter_y = center_y / float(net_h) * grid_h\n",
        "\t\t\t\tw = np.log((obj['xmax'] - obj['xmin']) / float(max_anchor.xmax))\n",
        "\t\t\t\th = np.log((obj['ymax'] - obj['ymin']) / float(max_anchor.ymax))\n",
        "\t\t\t\tbox = [center_x, center_y, w, h]\n",
        "\t\t\t\tobj_indx = self.labels.index(obj['name'])\n",
        "\t\t\t\tgrid_x = int(np.floor(center_x))\n",
        "\t\t\t\tgrid_y = int(np.floor(center_y))\n",
        "\t\t\t\tyolo[instance_count, grid_y, grid_x, max_index%3]      = 0\n",
        "\t\t\t\tyolo[instance_count, grid_y, grid_x, max_index%3, 0:4] = box\n",
        "\t\t\t\tyolo[instance_count, grid_y, grid_x, max_index%3, 4  ] = 1.\n",
        "\t\t\t\tyolo[instance_count, grid_y, grid_x, max_index%3, 5+obj_indx] = 1\n",
        "\t\t\t\ttrue_box = [center_x, center_y, obj['xmax'] - obj['xmin'], obj['ymax'] - obj['ymin']]\n",
        "\t\t\t\tt_batch[instance_count, 0, 0, 0, true_box_index] = true_box\n",
        "\t\t\t\ttrue_box_index += 1\n",
        "\t\t\t\ttrue_box_index = true_box_index % self.max_box_per_image\n",
        "\t\t\tif self.norm != None:\n",
        "\t\t\t\tx_batch[instance_count] = self.norm(img)\n",
        "\t\t\telse:\n",
        "\t\t\t\tfor obj in all_objs:\n",
        "\t\t\t\t\tcv2.rectangle(img, (obj['xmin'],obj['ymin']), (obj['xmax'],obj['ymax']), (255,0,0), 3)\n",
        "\t\t\t\t\tcv2.putText(img, obj['name'], (obj['xmin']+2, obj['ymin']+12), 0, 1.2e-3 * img.shape[0], (0,255,0), 2)\n",
        "\t\t\t\tx_batch[instance_count] = img\n",
        "\t\t\tinstance_count += 1\n",
        "\t\treturn [x_batch, t_batch, yolo_1, yolo_2, yolo_3], [dummy_yolo_1, dummy_yolo_2, dummy_yolo_3]\n",
        "\tdef _get_net_size(self, idx):\n",
        "\t\tif idx%10 == 0:\n",
        "\t\t\tnet_size = self.downsample*np.random.randint(self.min_net_size/self.downsample, self.max_net_size/self.downsample+1)\n",
        "\t\t\tprint('resizing: ', net_size, net_size)\n",
        "\t\t\tself.net_h, self.net_w = net_size, net_size\n",
        "\t\treturn self.net_h, self.net_w\n",
        "\tdef _aug_image(self, instance, net_h, net_w):\n",
        "\t\timage_name = instance['filename']\n",
        "\t\timage = cv2.imread(image_name)\n",
        "\t\tif image is None: print('Cannot find ', image_name)\n",
        "\t\timage = image[:,:,::-1]\n",
        "\t\timage_h, image_w, _ = image.shape\n",
        "\t\tdw = self.jitter * image_w;\n",
        "\t\tdh = self.jitter * image_h;\n",
        "\t\tnew_ar = (image_w + np.random.uniform(-dw, dw)) / (image_h + np.random.uniform(-dh, dh));\n",
        "\t\tscale = np.random.uniform(0.25, 2);\n",
        "\t\tif (new_ar < 1):\n",
        "\t\t\tnew_h = int(scale * net_h);\n",
        "\t\t\tnew_w = int(net_h * new_ar);\n",
        "\t\telse:\n",
        "\t\t\tnew_w = int(scale * net_w);\n",
        "\t\t\tnew_h = int(net_w / new_ar);\n",
        "\t\tdx = int(np.random.uniform(0, net_w - new_w));\n",
        "\t\tdy = int(np.random.uniform(0, net_h - new_h));\n",
        "\t\tim_sized = apply_random_scale_and_crop(image, new_w, new_h, net_w, net_h, dx, dy)\n",
        "\t\tim_sized = random_distort_image(im_sized)\n",
        "\t\tflip = np.random.randint(2)\n",
        "\t\tim_sized = random_flip(im_sized, flip)\n",
        "\t\tall_objs = correct_bounding_boxes(instance['object'], new_w, new_h, net_w, net_h, dx, dy, flip, image_w, image_h)\n",
        "\t\treturn im_sized, all_objs\n",
        "\tdef on_epoch_end(self):\n",
        "\t\tif self.shuffle: np.random.shuffle(self.instances)\n",
        "\tdef num_classes(self):\n",
        "\t\treturn len(self.labels)\n",
        "\tdef size(self):\n",
        "\t\treturn len(self.instances)\n",
        "\tdef get_anchors(self):\n",
        "\t\tanchors = []\n",
        "\t\tfor anchor in self.anchors:\n",
        "\t\t\tanchors += [anchor.xmax, anchor.ymax]\n",
        "\t\treturn anchors\n",
        "\tdef load_annotation(self, i):\n",
        "\t\tannots = []\n",
        "\t\tfor obj in self.instances[i]['object']:\n",
        "\t\t\tannot = [obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax'], self.labels.index(obj['name'])]\n",
        "\t\t\tannots += [annot]\n",
        "\t\tif len(annots) == 0: annots = [[]]\n",
        "\t\treturn np.array(annots)\n",
        "\tdef load_image(self, i):\n",
        "\t\treturn cv2.imread(self.instances[i]['filename'])\n",
        "def parse_voc_annotation(ann_dir, img_dir, cache_name, labels=[]):\n",
        "\tif os.path.exists(cache_name):\n",
        "\t\twith open(cache_name, 'rb') as handle:\n",
        "\t\t\tcache = pickle.load(handle)\n",
        "\t\tall_insts, seen_labels = cache['all_insts'], cache['seen_labels']\n",
        "\telse:\n",
        "\t\tall_insts = []\n",
        "\t\tseen_labels = {}\n",
        "\t\tfor ann in sorted(os.listdir(ann_dir)):\n",
        "\t\t\timg = {'object':[]}\n",
        "\t\t\ttry:\n",
        "\t\t\t\ttree = ET.parse(ann_dir + ann)\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\tprint(e)\n",
        "\t\t\t\tprint('Ignore this bad annotation: ' + ann_dir + ann)\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tfor elem in tree.iter():\n",
        "\t\t\t\tif 'filename' in elem.tag:\n",
        "\t\t\t\t\timg['filename'] = img_dir + elem.text\n",
        "\t\t\t\tif 'width' in elem.tag:\n",
        "\t\t\t\t\timg['width'] = int(elem.text)\n",
        "\t\t\t\tif 'height' in elem.tag:\n",
        "\t\t\t\t\timg['height'] = int(elem.text)\n",
        "\t\t\t\tif 'object' in elem.tag or 'part' in elem.tag:\n",
        "\t\t\t\t\tobj = {}\n",
        "\t\t\t\t\tfor attr in list(elem):\n",
        "\t\t\t\t\t\tif 'name' in attr.tag:\n",
        "\t\t\t\t\t\t\tobj['name'] = attr.text\n",
        "\t\t\t\t\t\t\tif obj['name'] in seen_labels:\n",
        "\t\t\t\t\t\t\t\tseen_labels[obj['name']] += 1\n",
        "\t\t\t\t\t\t\telse: seen_labels[obj['name']] = 1\n",
        "\t\t\t\t\t\t\tif len(labels) > 0 and obj['name'] not in labels: break\n",
        "\t\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\t\timg['object'] += [obj]\n",
        "\t\t\t\t\t\tif 'bndbox' in attr.tag:\n",
        "\t\t\t\t\t\t\tfor dim in list(attr):\n",
        "\t\t\t\t\t\t\t\tif 'xmin' in dim.tag: obj['xmin'] = int(round(float(dim.text)))\n",
        "\t\t\t\t\t\t\t\tif 'ymin' in dim.tag: obj['ymin'] = int(round(float(dim.text)))\n",
        "\t\t\t\t\t\t\t\tif 'xmax' in dim.tag: obj['xmax'] = int(round(float(dim.text)))\n",
        "\t\t\t\t\t\t\t\tif 'ymax' in dim.tag: obj['ymax'] = int(round(float(dim.text)))\n",
        "\t\t\tif len(img['object']) > 0:\n",
        "\t\t\t\tall_insts += [img]\n",
        "\t\tcache = {'all_insts': all_insts, 'seen_labels': seen_labels}\n",
        "\t\twith open(cache_name, 'wb') as handle:\n",
        "\t\t\tpickle.dump(cache, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\treturn all_insts, seen_labels\n",
        "\n",
        "class CustomTensorBoard(TensorBoard):\n",
        "\t'''\n",
        "\tTo log the loss after each batch\n",
        "\t'''\n",
        "\tdef __init__(self, log_every=1, **kwargs):\n",
        "\t\tsuper(CustomTensorBoard, self).__init__(**kwargs)\n",
        "\t\tself.log_every = log_every\n",
        "\t\tself.counter = 0\n",
        "\tdef on_batch_end(self, batch, logs=None):\n",
        "\t\tself.counter+=1\n",
        "\t\tif self.counter%self.log_every==0:\n",
        "\t\t\tfor name, value in logs.items():\n",
        "\t\t\t\tif name in ['batch', 'size']:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tsummary = tf.Summary()\n",
        "\t\t\t\tsummary_value = summary.value.add()\n",
        "\t\t\t\tsummary_value.simple_value = value.item()\n",
        "\t\t\t\tsummary_value.tag = name\n",
        "\t\t\t\tself.writer.add_summary(summary, self.counter)\n",
        "\t\t\tself.writer.flush()\n",
        "\t\tsuper(CustomTensorBoard, self).on_batch_end(batch, logs)\n",
        "\n",
        "class CustomModelCheckpoint(ModelCheckpoint):\n",
        "\t'''\n",
        "\tTo save the template model, not the multi-GPU model\n",
        "\t'''\n",
        "\tdef __init__(self, model_to_save, **kwargs):\n",
        "\t\tsuper(CustomModelCheckpoint, self).__init__(**kwargs)\n",
        "\t\tself.model_to_save = model_to_save\n",
        "\tdef on_epoch_end(self, epoch, logs=None):\n",
        "\t\tlogs = logs or {}\n",
        "\t\tself.epochs_since_last_save += 1\n",
        "\t\tif self.epochs_since_last_save >= self.period:\n",
        "\t\t\tself.epochs_since_last_save = 0\n",
        "\t\t\tfilepath = self.filepath.format(epoch=epoch + 1, **logs)\n",
        "\t\t\tif self.save_best_only:\n",
        "\t\t\t\tcurrent = logs.get(self.monitor)\n",
        "\t\t\t\tif current is None:\n",
        "\t\t\t\t\twarnings.warn('Can save best model only with %s available, '\n",
        "\t\t\t\t\t\t\t\t\t'skipping.' % (self.monitor), RuntimeWarning)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tif self.monitor_op(current, self.best):\n",
        "\t\t\t\t\t\tif self.verbose > 0:\n",
        "\t\t\t\t\t\t\tprint('\\nEpoch %05d: %s improved from %0.5f to %0.5f,'\n",
        "\t\t\t\t\t\t\t\t\t' saving model to %s' % (epoch + 1, self.monitor, self.best, current, filepath))\n",
        "\t\t\t\t\t\tself.best = current\n",
        "\t\t\t\t\t\tif self.save_weights_only:\n",
        "\t\t\t\t\t\t\tself.model_to_save.save_weights(filepath, overwrite=True)\n",
        "\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\tself.model_to_save.save(filepath, overwrite=True)\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tif self.verbose > 0:\n",
        "\t\t\t\t\t\t\tprint('\\nEpoch %05d: %s did not improve from %0.5f' % (epoch + 1, self.monitor, self.best))\n",
        "\t\t\telse:\n",
        "\t\t\t\tif self.verbose > 0:\n",
        "\t\t\t\t\tprint('\\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))\n",
        "\t\t\t\tif self.save_weights_only:\n",
        "\t\t\t\t\tself.model_to_save.save_weights(filepath, overwrite=True)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tself.model_to_save.save(filepath, overwrite=True)\n",
        "\t\tsuper(CustomModelCheckpoint, self).on_batch_end(epoch, logs)\n",
        "\n",
        "def create_training_instances(train_annot_folder, train_image_folder, train_cache, valid_annot_folder, valid_image_folder, valid_cache, labels,):\n",
        "\ttrain_ints, train_labels = parse_voc_annotation(train_annot_folder, train_image_folder, train_cache, labels)\n",
        "\tprint('valid_annot_folder not exists. Spliting the trainining set.')\n",
        "\ttrain_valid_split = int(0.8*len(train_ints))\n",
        "\tnp.random.seed(0)\n",
        "\tnp.random.shuffle(train_ints)\n",
        "\tnp.random.seed()\n",
        "\tvalid_ints = train_ints[train_valid_split:]\n",
        "\ttrain_ints = train_ints[:train_valid_split]\n",
        "\tif len(labels) > 0:\n",
        "\t\toverlap_labels = set(labels).intersection(set(train_labels.keys()))\n",
        "\t\tprint('Seen labels: \\t'  + str(train_labels) + '\\n')\n",
        "\t\tprint('Given labels: \\t' + str(labels))\n",
        "\t\tif len(overlap_labels) < len(labels):\n",
        "\t\t\tprint('Some labels have no annotations! Please revise the list of labels in the config.json.')\n",
        "\t\t\treturn None, None, None\n",
        "\telse:\n",
        "\t\tprint('No labels are provided. Train on all seen labels.')\n",
        "\t\tprint(train_labels)\n",
        "\t\tlabels = train_labels.keys()\n",
        "\tmax_box_per_image = max([len(inst['object']) for inst in (train_ints + valid_ints)])\n",
        "\treturn train_ints, valid_ints, sorted(labels), max_box_per_image\n",
        "\n",
        "def create_callbacks(saved_weights_name, tensorboard_logs, model_to_save):\n",
        "\tmakedirs(tensorboard_logs)\n",
        "\tearly_stop = EarlyStopping(\n",
        "\t\tmonitor         = 'loss',\n",
        "\t\tmin_delta       = 0.01,\n",
        "\t\tpatience        = 5,\n",
        "\t\tmode            = 'min',\n",
        "\t\tverbose         = 1)\n",
        "\tcheckpoint = CustomModelCheckpoint(\n",
        "\t\tmodel_to_save   = model_to_save,\n",
        "\t\tfilepath        = saved_weights_name,\n",
        "\t\tmonitor         = 'loss',\n",
        "\t\tverbose         = 1,\n",
        "\t\tsave_best_only  = True,\n",
        "\t\tmode            = 'min',\n",
        "\t\tperiod          = 1)\n",
        "\treduce_on_plateau = ReduceLROnPlateau(\n",
        "\t\tmonitor         = 'loss',\n",
        "\t\tfactor          = .1,\n",
        "\t\tpatience        = 2,\n",
        "\t\tverbose         = 1,\n",
        "\t\tmode            = 'min',\n",
        "\t\tepsilon         = 0.01,\n",
        "\t\tcooldown        = 0,\n",
        "\t\tmin_lr          = 0)\n",
        "\ttensorboard = CustomTensorBoard(\n",
        "\t\tlog_dir         = tensorboard_logs,\n",
        "\t\twrite_graph     = True,\n",
        "\t\twrite_images    = True,)\n",
        "\treturn [early_stop, checkpoint, reduce_on_plateau, tensorboard]\n",
        "\n",
        "def create_model(\n",
        "\tnb_class,\n",
        "\tanchors,\n",
        "\tmax_box_per_image,\n",
        "\tmax_grid, batch_size,\n",
        "\twarmup_batches,\n",
        "\tignore_thresh,\n",
        "\tmulti_gpu,\n",
        "\tsaved_weights_name,\n",
        "\tlr,\n",
        "\tgrid_scales,\n",
        "\tobj_scale,\n",
        "\tnoobj_scale,\n",
        "\txywh_scale,\n",
        "\tclass_scale):\n",
        "\tif multi_gpu > 1:\n",
        "\t\twith tf.device('/cpu:0'):\n",
        "\t\t\ttemplate_model, infer_model = create_yolov3_model(\n",
        "\t\t\t\tnb_class            = nb_class,\n",
        "\t\t\t\tanchors             = anchors,\n",
        "\t\t\t\tmax_box_per_image   = max_box_per_image,\n",
        "\t\t\t\tmax_grid            = max_grid,\n",
        "\t\t\t\tbatch_size          = batch_size//multi_gpu,\n",
        "\t\t\t\twarmup_batches      = warmup_batches,\n",
        "\t\t\t\tignore_thresh       = ignore_thresh,\n",
        "\t\t\t\tgrid_scales         = grid_scales,\n",
        "\t\t\t\tobj_scale           = obj_scale,\n",
        "\t\t\t\tnoobj_scale         = noobj_scale,\n",
        "\t\t\t\txywh_scale          = xywh_scale,\n",
        "\t\t\t\tclass_scale         = class_scale)\n",
        "\telse:\n",
        "\t\ttemplate_model, infer_model = create_yolov3_model(\n",
        "\t\t\tnb_class                = nb_class,\n",
        "\t\t\tanchors                 = anchors,\n",
        "\t\t\tmax_box_per_image       = max_box_per_image,\n",
        "\t\t\tmax_grid                = max_grid,\n",
        "\t\t\tbatch_size              = batch_size,\n",
        "\t\t\twarmup_batches          = warmup_batches,\n",
        "\t\t\tignore_thresh           = ignore_thresh,\n",
        "\t\t\tgrid_scales             = grid_scales,\n",
        "\t\t\tobj_scale               = obj_scale,\n",
        "\t\t\tnoobj_scale             = noobj_scale,\n",
        "\t\t\txywh_scale              = xywh_scale,\n",
        "\t\t\tclass_scale             = class_scale)\n",
        "\tif os.path.exists(saved_weights_name):\n",
        "\t\tprint('\\nLoading pretrained weights.\\n')\n",
        "\t\ttemplate_model.load_weights(saved_weights_name)\n",
        "\tif multi_gpu > 1:\n",
        "\t\ttrain_model = multi_gpu_model(template_model, gpus=multi_gpu)\n",
        "\telse:\n",
        "\t\ttrain_model = template_model\n",
        "\toptimizer = Adam(lr=lr, clipnorm=0.001)\n",
        "\ttrain_model.compile(loss=dummy_loss, optimizer=optimizer)\n",
        "\treturn train_model, infer_model\n",
        "\n",
        "def main_train():\n",
        "\ttrain_ints, valid_ints, labels, max_box_per_image = create_training_instances(\n",
        "\t\tconfig['train']['train_annot_folder'],\n",
        "\t\tconfig['train']['train_image_folder'],\n",
        "\t\tconfig['train']['cache_name'],\n",
        "\t\tconfig['valid']['valid_annot_folder'],\n",
        "\t\tconfig['valid']['valid_image_folder'],\n",
        "\t\tconfig['valid']['cache_name'],\n",
        "\t\tconfig['model']['labels'])\n",
        "\tprint('\\nTraining on: \\t' + str(labels) + '\\n')\n",
        "\ttrain_generator = BatchGenerator(\n",
        "\t\tinstances           = train_ints,\n",
        "\t\tanchors             = config['model']['anchors'],\n",
        "\t\tlabels              = labels,\n",
        "\t\tdownsample          = 32,\n",
        "\t\tmax_box_per_image   = max_box_per_image,\n",
        "\t\tbatch_size          = config['train']['batch_size'],\n",
        "\t\tmin_net_size        = config['model']['min_input_size'],\n",
        "\t\tmax_net_size        = config['model']['max_input_size'],\n",
        "\t\tshuffle             = True,\n",
        "\t\tjitter              = 0.3,\n",
        "\t\tnorm                = normalize)\n",
        "\tvalid_generator = BatchGenerator(\n",
        "\t\tinstances           = valid_ints,\n",
        "\t\tanchors             = config['model']['anchors'],\n",
        "\t\tlabels              = labels,\n",
        "\t\tdownsample          = 32,\n",
        "\t\tmax_box_per_image   = max_box_per_image,\n",
        "\t\tbatch_size          = config['train']['batch_size'],\n",
        "\t\tmin_net_size        = config['model']['min_input_size'],\n",
        "\t\tmax_net_size        = config['model']['max_input_size'],\n",
        "\t\tshuffle             = True,\n",
        "\t\tjitter              = 0.0,\n",
        "\t\tnorm                = normalize)\n",
        "\tif os.path.exists(config['train']['saved_weights_name']):\n",
        "\t\tconfig['train']['warmup_epochs'] = 0\n",
        "\twarmup_batches = config['train']['warmup_epochs'] * (config['train']['train_times']*len(train_generator))\n",
        "\tos.environ['CUDA_VISIBLE_DEVICES'] = config['train']['gpus']\n",
        "\tmulti_gpu = len(config['train']['gpus'].split(','))\n",
        "\ttrain_model, infer_model = create_model(\n",
        "\t\tnb_class             = len(labels),\n",
        "\t\tanchors              = config['model']['anchors'],\n",
        "\t\tmax_box_per_image    = max_box_per_image,\n",
        "\t\tmax_grid             = [config['model']['max_input_size'], config['model']['max_input_size']],\n",
        "\t\tbatch_size           = config['train']['batch_size'],\n",
        "\t\twarmup_batches       = warmup_batches,\n",
        "\t\tignore_thresh        = config['train']['ignore_thresh'],\n",
        "\t\tmulti_gpu            = multi_gpu,\n",
        "\t\tsaved_weights_name   = config['train']['saved_weights_name'],\n",
        "\t\tlr                   = config['train']['learning_rate'],\n",
        "\t\tgrid_scales          = config['train']['grid_scales'],\n",
        "\t\tobj_scale            = config['train']['obj_scale'],\n",
        "\t\tnoobj_scale          = config['train']['noobj_scale'],\n",
        "\t\txywh_scale           = config['train']['xywh_scale'],\n",
        "\t\tclass_scale          = config['train']['class_scale'],)\n",
        "\tcallbacks = create_callbacks(config['train']['saved_weights_name'], config['train']['tensorboard_dir'], infer_model)\n",
        "\ttrain_model.fit_generator(\n",
        "\t\tgenerator           = train_generator,\n",
        "\t\tsteps_per_epoch     = len(train_generator) * config['train']['train_times'],\n",
        "\t\tepochs              = config['train']['nb_epochs'] + config['train']['warmup_epochs'],\n",
        "\t\tverbose             = 1,\n",
        "\t\tcallbacks           = callbacks,\n",
        "\t\tworkers             = 4,\n",
        "\t\tmax_queue_size      = 8)\n",
        "\tif multi_gpu > 1:\n",
        "\t\tinfer_model = load_model(config['train']['saved_weights_name'])\n",
        "\taverage_precisions = evaluate(infer_model, valid_generator)\n",
        "\tfor label, average_precision in average_precisions.items():\n",
        "\t\tprint(labels[label] + ': {:.4f}'.format(average_precision))\n",
        "\tprint('mAP: {:.4f}'.format(sum(average_precisions.values()) / len(average_precisions)))\n",
        "\n",
        "def main_predict(WEIGHTS, FILENAME, output_path):\n",
        "\tconfig_path\t\t= config\n",
        "\tinput_path\t\t= FILENAME\n",
        "\tnet_h, net_w = 416, 416\n",
        "\tobj_thresh, nms_thresh = 0.5, 0.45\n",
        "\tos.environ['CUDA_VISIBLE_DEVICES'] = config['train']['gpus']\n",
        "\tinfer_model = load_model(WEIGHTS)\n",
        "\tif 'webcam' in input_path:\n",
        "\t\tvideo_reader = cv2.VideoCapture(0)\n",
        "\t\tbatch_size   = 1\n",
        "\t\timages       = []\n",
        "\t\twhile True:\n",
        "\t\t\tret_val, image = video_reader.read()\n",
        "\t\t\tif ret_val == True: images += [image]\n",
        "\t\t\tif (len(images)==batch_size) or (ret_val==False and len(images)>0):\n",
        "\t\t\t\tbatch_boxes = get_yolo_boxes(infer_model, images, net_h, net_w, config['model']['anchors'], obj_thresh, nms_thresh)\n",
        "\t\t\t\tfor i in range(len(images)):\n",
        "\t\t\t\t\tdraw_boxes(images[i], batch_boxes[i], config['model']['labels'], obj_thresh)\n",
        "\t\t\t\t\tcv2.imshow('video with bboxes', images[i])\n",
        "\t\t\t\timages = []\n",
        "\t\t\tif cv2.waitKey(1) == 27:\n",
        "\t\t\t\tbreak \n",
        "\t\tcv2.destroyAllWindows()\n",
        "\telif input_path[-4:] == '.mp4':\n",
        "\t\tvideo_out = output_path + input_path.split('/')[-1]\n",
        "\t\tvideo_reader = cv2.VideoCapture(input_path)\n",
        "\t\tnb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\t\tframe_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\t\tframe_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "\t\tvideo_writer = cv2.VideoWriter(video_out, cv2.VideoWriter_fourcc(*'MPEG'), 50.0, (frame_w, frame_h))\n",
        "\t\tbatch_size  = 1\n",
        "\t\timages      = []\n",
        "\t\tstart_point = 0\n",
        "\t\tshow_window = False\n",
        "\t\tfor i in tqdm(range(nb_frames)):\n",
        "\t\t\t_, image = video_reader.read()\n",
        "\t\t\tif (float(i+1)/nb_frames) > start_point/100.:\n",
        "\t\t\t\timages += [image]\n",
        "\t\t\t\tif (i%batch_size == 0) or (i == (nb_frames-1) and len(images) > 0):\n",
        "\t\t\t\t\tbatch_boxes = get_yolo_boxes(infer_model, images, net_h, net_w, config['model']['anchors'], obj_thresh, nms_thresh)\n",
        "\t\t\t\t\tfor i in range(len(images)):\n",
        "\t\t\t\t\t\tdraw_boxes(images[i], batch_boxes[i], config['model']['labels'], obj_thresh)\n",
        "\t\t\t\t\t\tif show_window: cv2.imshow('video with bboxes', images[i])\n",
        "\t\t\t\t\t\tvideo_writer.write(images[i]) \n",
        "\t\t\t\t\timages = []\n",
        "\t\t\t\tif show_window and cv2.waitKey(1) == 27: break\n",
        "\t\tif show_window: cv2.destroyAllWindows()\n",
        "\t\tvideo_reader.release()\n",
        "\t\tvideo_writer.release()\n",
        "\telse:\n",
        "\t\timage_paths = []\n",
        "\t\tif os.path.isdir(input_path):\n",
        "\t\t\tfor inp_file in os.listdir(input_path):\n",
        "\t\t\t\timage_paths += [input_path + inp_file]\n",
        "\t\telse:\n",
        "\t\t\timage_paths += [input_path]\n",
        "\t\timage_paths = [inp_file for inp_file in image_paths if (inp_file[-4:] in ['.jpg', '.png', 'JPEG'])]\n",
        "\t\tfor image_path in image_paths:\n",
        "\t\t\timage = cv2.imread(image_path)\n",
        "\t\t\tprint(image_path)\n",
        "\t\t\tboxes = get_yolo_boxes(infer_model, [image], net_h, net_w, config['model']['anchors'], obj_thresh, nms_thresh)[0]\n",
        "\t\t\tdraw_boxes(image, boxes, config['model']['labels'], obj_thresh)\n",
        "\t\t\tcv2.imwrite(output_path + image_path.split('/')[-1], np.uint8(image))\n",
        "\n",
        "main_train()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "valid_annot_folder not exists. Spliting the trainining set.\n",
            "Seen labels: \t{'Paramecium': 63}\n",
            "\n",
            "Given labels: \t['Paramecium']\n",
            "\n",
            "Training on: \t['Paramecium']\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From <ipython-input-4-aeb9daaa0fe9>:66: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.6/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "resizing:  320 320\n",
            "Epoch 1/1000\n",
            " 6/96 [>.............................] - ETA: 15:56 - loss: 215.0587 - yolo_layer_1_loss: 25.6083 - yolo_layer_2_loss: 61.8071 - yolo_layer_3_loss: 127.6433resizing:  416 416\n",
            "11/96 [==>...........................] - ETA: 9:10 - loss: 199.9084 - yolo_layer_1_loss: 23.4305 - yolo_layer_2_loss: 57.5256 - yolo_layer_3_loss: 118.9524 resizing:  352 352\n",
            "17/96 [====>.........................] - ETA: 6:35 - loss: 205.4871 - yolo_layer_1_loss: 23.8153 - yolo_layer_2_loss: 58.8670 - yolo_layer_3_loss: 122.8048resizing:  448 448\n",
            "24/96 [======>.......................] - ETA: 5:05 - loss: 204.9217 - yolo_layer_1_loss: 23.3314 - yolo_layer_2_loss: 58.2537 - yolo_layer_3_loss: 123.3366resizing:  320 320\n",
            "29/96 [========>.....................] - ETA: 4:13 - loss: 205.7620 - yolo_layer_1_loss: 23.1465 - yolo_layer_2_loss: 58.1503 - yolo_layer_3_loss: 124.4653resizing:  448 448\n",
            "35/96 [=========>....................] - ETA: 3:29 - loss: 201.1137 - yolo_layer_1_loss: 22.4346 - yolo_layer_2_loss: 56.4150 - yolo_layer_3_loss: 122.2641resizing:  288 288\n",
            "41/96 [===========>..................] - ETA: 2:57 - loss: 193.8258 - yolo_layer_1_loss: 21.3950 - yolo_layer_2_loss: 54.0771 - yolo_layer_3_loss: 118.3537resizing:  384 384\n",
            "47/96 [=============>................] - ETA: 2:32 - loss: 188.7177 - yolo_layer_1_loss: 20.5324 - yolo_layer_2_loss: 52.4663 - yolo_layer_3_loss: 115.7190resizing:  384 384\n",
            "54/96 [===============>..............] - ETA: 2:02 - loss: 183.4385 - yolo_layer_1_loss: 19.7061 - yolo_layer_2_loss: 50.8065 - yolo_layer_3_loss: 112.9259resizing:  448 448\n",
            "60/96 [=================>............] - ETA: 1:40 - loss: 179.7064 - yolo_layer_1_loss: 19.0815 - yolo_layer_2_loss: 49.6800 - yolo_layer_3_loss: 110.9448resizing:  384 384\n",
            "66/96 [===================>..........] - ETA: 1:21 - loss: 176.1105 - yolo_layer_1_loss: 18.6005 - yolo_layer_2_loss: 48.6000 - yolo_layer_3_loss: 108.9100resizing:  288 288\n",
            "71/96 [=====================>........] - ETA: 1:05 - loss: 172.2191 - yolo_layer_1_loss: 18.0562 - yolo_layer_2_loss: 47.5106 - yolo_layer_3_loss: 106.6523resizing:  384 384\n",
            "77/96 [=======================>......] - ETA: 48s - loss: 166.8316 - yolo_layer_1_loss: 17.3462 - yolo_layer_2_loss: 45.9909 - yolo_layer_3_loss: 103.4945resizing:  416 416\n",
            "83/96 [========================>.....] - ETA: 32s - loss: 162.5472 - yolo_layer_1_loss: 16.7852 - yolo_layer_2_loss: 44.7903 - yolo_layer_3_loss: 100.9717resizing:  416 416\n",
            "90/96 [===========================>..] - ETA: 14s - loss: 157.9588 - yolo_layer_1_loss: 16.1860 - yolo_layer_2_loss: 43.4972 - yolo_layer_3_loss: 98.2756resizing:  416 416\n",
            "95/96 [============================>.] - ETA: 2s - loss: 154.8275 - yolo_layer_1_loss: 15.8686 - yolo_layer_2_loss: 42.5923 - yolo_layer_3_loss: 96.3666resizing:  352 352\n",
            "96/96 [==============================] - 230s 2s/step - loss: 154.2403 - yolo_layer_1_loss: 15.7809 - yolo_layer_2_loss: 42.4313 - yolo_layer_3_loss: 96.0281\n",
            "\n",
            "Epoch 00001: loss improved from inf to 154.24032, saving model to ./weights.h5\n",
            "Epoch 2/1000\n",
            " 5/96 [>.............................] - ETA: 1:36 - loss: 83.4476 - yolo_layer_1_loss: 7.3494 - yolo_layer_2_loss: 22.9131 - yolo_layer_3_loss: 53.1851resizing:  288 288\n",
            "11/96 [==>...........................] - ETA: 1:55 - loss: 77.0975 - yolo_layer_1_loss: 6.5236 - yolo_layer_2_loss: 21.4661 - yolo_layer_3_loss: 49.1079resizing:  448 448\n",
            "17/96 [====>.........................] - ETA: 1:56 - loss: 76.8022 - yolo_layer_1_loss: 7.3606 - yolo_layer_2_loss: 21.1843 - yolo_layer_3_loss: 48.2573resizing:  288 288\n",
            "23/96 [======>.......................] - ETA: 1:50 - loss: 74.8904 - yolo_layer_1_loss: 7.2390 - yolo_layer_2_loss: 20.7358 - yolo_layer_3_loss: 46.9155resizing:  352 352\n",
            "29/96 [========>.....................] - ETA: 1:42 - loss: 71.3933 - yolo_layer_1_loss: 7.0388 - yolo_layer_2_loss: 19.7482 - yolo_layer_3_loss: 44.6063resizing:  416 416\n",
            "36/96 [==========>...................] - ETA: 1:34 - loss: 69.8725 - yolo_layer_1_loss: 7.0975 - yolo_layer_2_loss: 19.3317 - yolo_layer_3_loss: 43.4432resizing:  352 352\n",
            "42/96 [============>.................] - ETA: 1:26 - loss: 68.9635 - yolo_layer_1_loss: 7.1104 - yolo_layer_2_loss: 19.1015 - yolo_layer_3_loss: 42.7516resizing:  448 448\n",
            "47/96 [=============>................] - ETA: 1:18 - loss: 67.4046 - yolo_layer_1_loss: 6.8614 - yolo_layer_2_loss: 18.7335 - yolo_layer_3_loss: 41.8096resizing:  416 416\n",
            "53/96 [===============>..............] - ETA: 1:09 - loss: 66.5393 - yolo_layer_1_loss: 7.0157 - yolo_layer_2_loss: 18.4045 - yolo_layer_3_loss: 41.1191resizing:  416 416\n",
            "60/96 [=================>............] - ETA: 58s - loss: 65.2796 - yolo_layer_1_loss: 7.1685 - yolo_layer_2_loss: 18.0191 - yolo_layer_3_loss: 40.0919 resizing:  416 416\n",
            "66/96 [===================>..........] - ETA: 49s - loss: 64.2284 - yolo_layer_1_loss: 7.4133 - yolo_layer_2_loss: 17.6055 - yolo_layer_3_loss: 39.2097resizing:  384 384\n",
            "71/96 [=====================>........] - ETA: 40s - loss: 63.2481 - yolo_layer_1_loss: 7.3653 - yolo_layer_2_loss: 17.3699 - yolo_layer_3_loss: 38.5128resizing:  416 416\n",
            "77/96 [=======================>......] - ETA: 31s - loss: 62.1278 - yolo_layer_1_loss: 7.4284 - yolo_layer_2_loss: 17.0148 - yolo_layer_3_loss: 37.6846resizing:  384 384\n",
            "83/96 [========================>.....] - ETA: 21s - loss: 61.0839 - yolo_layer_1_loss: 7.4526 - yolo_layer_2_loss: 16.6841 - yolo_layer_3_loss: 36.9472resizing:  416 416\n",
            "89/96 [==========================>...] - ETA: 11s - loss: 60.0044 - yolo_layer_1_loss: 7.4624 - yolo_layer_2_loss: 16.3532 - yolo_layer_3_loss: 36.1888resizing:  448 448\n",
            "95/96 [============================>.] - ETA: 1s - loss: 59.1955 - yolo_layer_1_loss: 7.6477 - yolo_layer_2_loss: 16.0496 - yolo_layer_3_loss: 35.4982resizing:  448 448\n",
            "96/96 [==============================] - 160s 2s/step - loss: 59.0730 - yolo_layer_1_loss: 7.6643 - yolo_layer_2_loss: 15.9914 - yolo_layer_3_loss: 35.4173\n",
            "\n",
            "Epoch 00002: loss improved from 154.24032 to 59.07300, saving model to ./weights.h5\n",
            "Epoch 3/1000\n",
            " 5/96 [>.............................] - ETA: 2:08 - loss: 44.5337 - yolo_layer_1_loss: 8.5248 - yolo_layer_2_loss: 11.2395 - yolo_layer_3_loss: 24.7694resizing:  288 288\n",
            "11/96 [==>...........................] - ETA: 2:12 - loss: 45.6547 - yolo_layer_1_loss: 10.9024 - yolo_layer_2_loss: 10.4744 - yolo_layer_3_loss: 24.2778resizing:  448 448\n",
            "18/96 [====>.........................] - ETA: 2:05 - loss: 42.4126 - yolo_layer_1_loss: 8.7127 - yolo_layer_2_loss: 10.2214 - yolo_layer_3_loss: 23.4785resizing:  320 320\n",
            "23/96 [======>.......................] - ETA: 1:58 - loss: 42.6152 - yolo_layer_1_loss: 8.9698 - yolo_layer_2_loss: 10.1310 - yolo_layer_3_loss: 23.5144resizing:  320 320\n",
            "29/96 [========>.....................] - ETA: 1:48 - loss: 40.7367 - yolo_layer_1_loss: 8.1162 - yolo_layer_2_loss: 9.5853 - yolo_layer_3_loss: 23.0352resizing:  384 384\n",
            "35/96 [=========>....................] - ETA: 1:38 - loss: 40.2972 - yolo_layer_1_loss: 7.9865 - yolo_layer_2_loss: 9.5598 - yolo_layer_3_loss: 22.7509resizing:  320 320\n",
            "41/96 [===========>..................] - ETA: 1:28 - loss: 39.3755 - yolo_layer_1_loss: 7.4658 - yolo_layer_2_loss: 9.6052 - yolo_layer_3_loss: 22.3045resizing:  416 416\n",
            "47/96 [=============>................] - ETA: 1:19 - loss: 38.5005 - yolo_layer_1_loss: 7.0101 - yolo_layer_2_loss: 9.5227 - yolo_layer_3_loss: 21.9677resizing:  320 320\n",
            "53/96 [===============>..............] - ETA: 1:09 - loss: 37.7883 - yolo_layer_1_loss: 6.8079 - yolo_layer_2_loss: 9.3121 - yolo_layer_3_loss: 21.6683resizing:  320 320\n",
            "60/96 [=================>............] - ETA: 58s - loss: 37.1856 - yolo_layer_1_loss: 6.7369 - yolo_layer_2_loss: 9.1686 - yolo_layer_3_loss: 21.2801 resizing:  288 288\n",
            "66/96 [===================>..........] - ETA: 48s - loss: 36.8168 - yolo_layer_1_loss: 6.7936 - yolo_layer_2_loss: 9.0392 - yolo_layer_3_loss: 20.9840resizing:  320 320\n",
            "71/96 [=====================>........] - ETA: 40s - loss: 36.2942 - yolo_layer_1_loss: 6.5841 - yolo_layer_2_loss: 9.0322 - yolo_layer_3_loss: 20.6779resizing:  320 320\n",
            "77/96 [=======================>......] - ETA: 30s - loss: 35.7260 - yolo_layer_1_loss: 6.2257 - yolo_layer_2_loss: 9.0276 - yolo_layer_3_loss: 20.4727resizing:  320 320\n",
            "83/96 [========================>.....] - ETA: 20s - loss: 35.7412 - yolo_layer_1_loss: 6.3303 - yolo_layer_2_loss: 9.0734 - yolo_layer_3_loss: 20.3375resizing:  416 416\n",
            "89/96 [==========================>...] - ETA: 11s - loss: 35.4954 - yolo_layer_1_loss: 6.3284 - yolo_layer_2_loss: 9.0351 - yolo_layer_3_loss: 20.1319resizing:  416 416\n",
            "95/96 [============================>.] - ETA: 1s - loss: 35.3080 - yolo_layer_1_loss: 6.4087 - yolo_layer_2_loss: 8.9234 - yolo_layer_3_loss: 19.9759resizing:  352 352\n",
            "96/96 [==============================] - 156s 2s/step - loss: 35.2676 - yolo_layer_1_loss: 6.4173 - yolo_layer_2_loss: 8.8890 - yolo_layer_3_loss: 19.9613\n",
            "\n",
            "Epoch 00003: loss improved from 59.07300 to 35.26761, saving model to ./weights.h5\n",
            "Epoch 4/1000\n",
            " 5/96 [>.............................] - ETA: 1:51 - loss: 30.6735 - yolo_layer_1_loss: 6.3144 - yolo_layer_2_loss: 6.5919 - yolo_layer_3_loss: 17.7671resizing:  448 448\n",
            " 8/96 [=>............................] - ETA: 2:22 - loss: 31.2236 - yolo_layer_1_loss: 6.6453 - yolo_layer_2_loss: 8.1396 - yolo_layer_3_loss: 16.4388"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-aeb9daaa0fe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1186\u001b[0m                         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m \u001b[0mmain_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-aeb9daaa0fe9>\u001b[0m in \u001b[0;36mmain_train\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1114\u001b[0m                 \u001b[0mcallbacks\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                 \u001b[0mworkers\u001b[0m             \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m \t\tmax_queue_size      = 8)\n\u001b[0m\u001b[1;32m   1117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmulti_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0minfer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'saved_weights_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}