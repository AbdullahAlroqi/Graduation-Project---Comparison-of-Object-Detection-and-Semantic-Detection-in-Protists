{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ek_mcGYIGzpN",
        "i6S_v3j1JvFz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek_mcGYIGzpN"
      },
      "source": [
        "# Import the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn3pS-NeKvV1"
      },
      "source": [
        "!wget -q https://www.dropbox.com/s/8conv524x6xid27/dataset.tar.bz2?dl=0 && mv \"dataset.tar.bz2?dl=0\" \"dataset.tar.bz2\" && tar -jxf dataset.tar.bz2 && rm dataset.tar.bz2\n",
        "!wget -q https://www.dropbox.com/s/eipq0l101wcjwyk/weights.h5?dl=0 && mv weights.h5?dl=0 weights.h5\n",
        "!rm -r sample_data/"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6S_v3j1JvFz"
      },
      "source": [
        "# Object detection training (Yolov3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oZ8AB1P5WUk"
      },
      "source": [
        "#Runtime > Restart runtime\n",
        "%tensorflow_version 1.x \n",
        "\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import copy\n",
        "import json\n",
        "import scipy\n",
        "import keras\n",
        "import pickle\n",
        "import argparse\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import xml.etree.ElementTree as ET\n",
        "from keras.utils import Sequence\n",
        "from keras.optimizers import Adam\n",
        "from keras.engine.topology import Layer\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.layers import Lambda, concatenate, ZeroPadding2D, UpSampling2D, Lambda, Conv2D, Input, BatchNormalization, LeakyReLU\n",
        "\n",
        "config = {\"model\":{\n",
        "\t\t\t\"min_input_size\":       288,\n",
        "\t\t\t\"max_input_size\":       448,\n",
        "\t\t\t\"anchors\":              [55,69,75,234,133,240,136,129,142,363,203,290,228,184,285,359,341,260],\n",
        "\t\t\t\"labels\":               ['Ceratium', 'Coleps', 'Collodictyon', 'Colsterium', 'Cylindrocystis', 'Didinium', 'Dinobryon', 'Frontonia', 'Lepocinclis', 'Micrasterias', 'Paramecium', 'Peridinium', 'Phacus', 'Pinnularia', 'Pleurotaenium', 'Pyrocystis', 'Volvox']},\n",
        "\t\t\"train\":{\n",
        "\t\t\t\"train_image_folder\":   \"./dataset/Train/\",\n",
        "\t\t\t\"train_annot_folder\":   \"./dataset/Annotations/\",\n",
        "\t\t\t\"tensorboard_dir\":      \"./logs\",\n",
        "\t\t\t\"saved_weights_name\":   \"./weights.h5\",\n",
        "\t\t\t\"cache_name\":           \"./training.pkl\",\n",
        "\t\t\t\"pretrained_weights\":   \"\",\n",
        "\t\t\t\"train_times\":          16,\n",
        "\t\t\t\"batch_size\":           8,\n",
        "\t\t\t\"learning_rate\":        1e-4,\n",
        "\t\t\t\"nb_epochs\":            100,\n",
        "\t\t\t\"warmup_epochs\":        0,\n",
        "\t\t\t\"ignore_thresh\":        0.5,\n",
        "\t\t\t\"gpus\":                 \"0,1\",\n",
        "\t\t\t\"grid_scales\":          [1,1,1],\n",
        "\t\t\t\"obj_scale\":            5,\n",
        "\t\t\t\"noobj_scale\":          1,\n",
        "\t\t\t\"xywh_scale\":           1,\n",
        "\t\t\t\"class_scale\":          1,\n",
        "\t\t\t\"debug\":                False},\n",
        "\t\t\"valid\":{\n",
        "\t\t\t\"valid_image_folder\":   \"./dataset/Valid/\",\n",
        "\t\t\t\"valid_annot_folder\":   \"./dataset/Valid_Annotations/\",\n",
        "\t\t\t\"cache_name\":           \"\",\n",
        "\t\t\t\"valid_times\":          1}}\n",
        "\n",
        "class YoloLayer(Layer):\n",
        "\tdef __init__(self, anchors, max_grid, batch_size, warmup_batches, ignore_thresh, grid_scale, obj_scale, noobj_scale, xywh_scale, class_scale, **kwargs):\n",
        "\t\tself.ignore_thresh  = ignore_thresh\n",
        "\t\tself.warmup_batches = warmup_batches\n",
        "\t\tself.anchors        = tf.constant(anchors, dtype='float', shape=[1,1,1,3,2])\n",
        "\t\tself.grid_scale     = grid_scale\n",
        "\t\tself.obj_scale      = obj_scale\n",
        "\t\tself.noobj_scale    = noobj_scale\n",
        "\t\tself.xywh_scale     = xywh_scale\n",
        "\t\tself.class_scale    = class_scale\n",
        "\t\tmax_grid_h, max_grid_w = max_grid\n",
        "\t\tcell_x = tf.to_float(tf.reshape(tf.tile(tf.range(max_grid_w), [max_grid_h]), (1, max_grid_h, max_grid_w, 1, 1)))\n",
        "\t\tcell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
        "\t\tself.cell_grid = tf.tile(tf.concat([cell_x,cell_y],-1), [batch_size, 1, 1, 3, 1])\n",
        "\t\tsuper(YoloLayer, self).__init__(**kwargs)\n",
        "\tdef build(self, input_shape):\n",
        "\t\tsuper(YoloLayer, self).build(input_shape)\n",
        "\tdef call(self, x):\n",
        "\t\tinput_image, y_pred, y_true, true_boxes = x\n",
        "\t\ty_pred = tf.reshape(y_pred, tf.concat([tf.shape(y_pred)[:3], tf.constant([3, -1])], axis=0))\n",
        "\t\tobject_mask     = tf.expand_dims(y_true[..., 4], 4)\n",
        "\t\tbatch_seen = tf.Variable(0.)\n",
        "\t\tgrid_h          = tf.shape(y_true)[1]\n",
        "\t\tgrid_w          = tf.shape(y_true)[2]\n",
        "\t\tgrid_factor     = tf.reshape(tf.cast([grid_w, grid_h], tf.float32), [1,1,1,1,2])\n",
        "\t\tnet_h           = tf.shape(input_image)[1]\n",
        "\t\tnet_w           = tf.shape(input_image)[2]\n",
        "\t\tnet_factor      = tf.reshape(tf.cast([net_w, net_h], tf.float32), [1,1,1,1,2])\n",
        "\t\tpred_box_xy     = (self.cell_grid[:,:grid_h,:grid_w,:,:] + tf.sigmoid(y_pred[..., :2]))\n",
        "\t\tpred_box_wh     = y_pred[..., 2:4]\n",
        "\t\tpred_box_conf   = tf.expand_dims(tf.sigmoid(y_pred[..., 4]), 4)\n",
        "\t\tpred_box_class  = y_pred[..., 5:]\n",
        "\t\ttrue_box_xy     = y_true[..., 0:2]\n",
        "\t\ttrue_box_wh     = y_true[..., 2:4]\n",
        "\t\ttrue_box_conf   = tf.expand_dims(y_true[..., 4], 4)\n",
        "\t\ttrue_box_class  = tf.argmax(y_true[..., 5:], -1)\n",
        "\t\tconf_delta      = pred_box_conf - 0\n",
        "\t\ttrue_xy         = true_boxes[..., 0:2] / grid_factor\n",
        "\t\ttrue_wh         = true_boxes[..., 2:4] / net_factor\n",
        "\t\ttrue_wh_half    = true_wh / 2.\n",
        "\t\ttrue_mins       = true_xy - true_wh_half\n",
        "\t\ttrue_maxes      = true_xy + true_wh_half\n",
        "\t\tpred_xy         = tf.expand_dims(pred_box_xy / grid_factor, 4)\n",
        "\t\tpred_wh         = tf.expand_dims(tf.exp(pred_box_wh) * self.anchors / net_factor, 4)\n",
        "\t\tpred_wh_half    = pred_wh / 2.\n",
        "\t\tpred_mins       = pred_xy - pred_wh_half\n",
        "\t\tpred_maxes      = pred_xy + pred_wh_half\n",
        "\t\tintersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "\t\tintersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "\t\tintersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "\t\tintersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "\t\ttrue_areas      = true_wh[..., 0] * true_wh[..., 1]\n",
        "\t\tpred_areas      = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "\t\tunion_areas     = pred_areas + true_areas - intersect_areas\n",
        "\t\tiou_scores      = tf.truediv(intersect_areas, union_areas)\n",
        "\t\tbest_ious       = tf.reduce_max(iou_scores, axis=4)\n",
        "\t\tconf_delta     *= tf.expand_dims(tf.to_float(best_ious < self.ignore_thresh), 4)\n",
        "\t\ttrue_xy         = true_box_xy / grid_factor\n",
        "\t\ttrue_wh         = tf.exp(true_box_wh) * self.anchors / net_factor\n",
        "\t\ttrue_wh_half    = true_wh / 2.\n",
        "\t\ttrue_mins       = true_xy - true_wh_half\n",
        "\t\ttrue_maxes      = true_xy + true_wh_half\n",
        "\t\tpred_xy         = pred_box_xy / grid_factor\n",
        "\t\tpred_wh         = tf.exp(pred_box_wh) * self.anchors / net_factor\n",
        "\t\tpred_wh_half    = pred_wh / 2.\n",
        "\t\tpred_mins       = pred_xy - pred_wh_half\n",
        "\t\tpred_maxes      = pred_xy + pred_wh_half\n",
        "\t\tintersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "\t\tintersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "\t\tintersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "\t\tintersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "\t\ttrue_areas      = true_wh[..., 0] * true_wh[..., 1]\n",
        "\t\tpred_areas      = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "\t\tunion_areas     = pred_areas + true_areas - intersect_areas\n",
        "\t\tiou_scores      = tf.truediv(intersect_areas, union_areas)\n",
        "\t\tiou_scores      = object_mask * tf.expand_dims(iou_scores, 4)\n",
        "\t\tcount           = tf.reduce_sum(object_mask)\n",
        "\t\tcount_noobj     = tf.reduce_sum(1 - object_mask)\n",
        "\t\tdetect_mask     = tf.to_float((pred_box_conf*object_mask) >= 0.5)\n",
        "\t\tclass_mask      = tf.expand_dims(tf.to_float(tf.equal(tf.argmax(pred_box_class, -1), true_box_class)), 4)\n",
        "\t\trecall50        = tf.reduce_sum(tf.to_float(iou_scores >= 0.5 ) * detect_mask  * class_mask) / (count + 1e-3)\n",
        "\t\trecall75        = tf.reduce_sum(tf.to_float(iou_scores >= 0.75) * detect_mask  * class_mask) / (count + 1e-3)\n",
        "\t\tavg_iou         = tf.reduce_sum(iou_scores) / (count + 1e-3)\n",
        "\t\tavg_obj         = tf.reduce_sum(pred_box_conf  * object_mask)  / (count + 1e-3)\n",
        "\t\tavg_noobj       = tf.reduce_sum(pred_box_conf  * (1-object_mask))  / (count_noobj + 1e-3)\n",
        "\t\tavg_cat         = tf.reduce_sum(object_mask * class_mask) / (count + 1e-3)\n",
        "\t\tbatch_seen      = tf.assign_add(batch_seen, 1.)\n",
        "\t\ttrue_box_xy, true_box_wh, xywh_mask = tf.cond(tf.less(batch_seen, self.warmup_batches+1), lambda: [true_box_xy + (0.5 + self.cell_grid[:,:grid_h,:grid_w,:,:]) * (1-object_mask), true_box_wh + tf.zeros_like(true_box_wh) * (1-object_mask), tf.ones_like(object_mask)], lambda: [true_box_xy, true_box_wh, object_mask])\n",
        "\t\twh_scale        = tf.exp(true_box_wh) * self.anchors / net_factor\n",
        "\t\twh_scale        = tf.expand_dims(2 - wh_scale[..., 0] * wh_scale[..., 1], axis=4)\n",
        "\t\txy_delta        = xywh_mask     * (pred_box_xy-true_box_xy) * wh_scale * self.xywh_scale\n",
        "\t\twh_delta        = xywh_mask     * (pred_box_wh-true_box_wh) * wh_scale * self.xywh_scale\n",
        "\t\tconf_delta      = object_mask   * (pred_box_conf-true_box_conf) * self.obj_scale + (1-object_mask) * conf_delta * self.noobj_scale\n",
        "\t\tclass_delta     = object_mask   * tf.expand_dims(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class), 4) * self.class_scale\n",
        "\t\tloss_xy         = tf.reduce_sum(tf.square(xy_delta),        list(range(1,5)))\n",
        "\t\tloss_wh         = tf.reduce_sum(tf.square(wh_delta),        list(range(1,5)))\n",
        "\t\tloss_conf       = tf.reduce_sum(tf.square(conf_delta),      list(range(1,5)))\n",
        "\t\tloss_class      = tf.reduce_sum(class_delta,                list(range(1,5)))\n",
        "\t\tloss            = loss_xy + loss_wh + loss_conf + loss_class\n",
        "\t\tif config['train']['debug']:\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, avg_obj], message='avg_obj \\t\\t', summarize=1000)\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, avg_noobj], message='avg_noobj \\t\\t', summarize=1000)\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, avg_iou], message='avg_iou \\t\\t', summarize=1000)\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, avg_cat], message='avg_cat \\t\\t', summarize=1000)\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, recall50], message='recall50 \\t', summarize=1000)\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, recall75], message='recall75 \\t', summarize=1000)\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, count], message='count \\t', summarize=1000)\n",
        "\t\t\tloss        = tf.Print(loss, [grid_h, tf.reduce_sum(loss_xy), tf.reduce_sum(loss_wh), tf.reduce_sum(loss_conf), tf.reduce_sum(loss_class)], message='loss xy, wh, conf, class: \\t', summarize=1000)\n",
        "\t\treturn loss*self.grid_scale\n",
        "\tdef compute_output_shape(self, input_shape):\n",
        "\t\treturn [(None, 1)]\n",
        "\n",
        "def _rand_scale(scale):\n",
        "\tscale = np.random.uniform(1, scale)\n",
        "\treturn scale if (np.random.randint(2) == 0) else 1./scale;\n",
        "\n",
        "def _constrain(min_v, max_v, value):\n",
        "\tif value < min_v: return min_v\n",
        "\tif value > max_v: return max_v\n",
        "\treturn value\n",
        "\n",
        "def random_flip(image, flip):\n",
        "\tif flip == 1: return cv2.flip(image, 1)\n",
        "\treturn image\n",
        "\n",
        "def correct_bounding_boxes(boxes, new_w, new_h, net_w, net_h, dx, dy, flip, image_w, image_h):\n",
        "\tboxes = copy.deepcopy(boxes)\n",
        "\tnp.random.shuffle(boxes)\n",
        "\tsx, sy = float(new_w)/image_w, float(new_h)/image_h\n",
        "\tzero_boxes = []\n",
        "\tfor i in range(len(boxes)):\n",
        "\t\tboxes[i]['xmin'] = int(_constrain(0, net_w, boxes[i]['xmin']*sx + dx))\n",
        "\t\tboxes[i]['xmax'] = int(_constrain(0, net_w, boxes[i]['xmax']*sx + dx))\n",
        "\t\tboxes[i]['ymin'] = int(_constrain(0, net_h, boxes[i]['ymin']*sy + dy))\n",
        "\t\tboxes[i]['ymax'] = int(_constrain(0, net_h, boxes[i]['ymax']*sy + dy))\n",
        "\t\tif boxes[i]['xmax'] <= boxes[i]['xmin'] or boxes[i]['ymax'] <= boxes[i]['ymin']:\n",
        "\t\t\tzero_boxes += [i]\n",
        "\t\t\tcontinue\n",
        "\t\tif flip == 1:\n",
        "\t\t\tswap = boxes[i]['xmin'];\n",
        "\t\t\tboxes[i]['xmin'] = net_w - boxes[i]['xmax']\n",
        "\t\t\tboxes[i]['xmax'] = net_w - swap\n",
        "\tboxes = [boxes[i] for i in range(len(boxes)) if i not in zero_boxes]\n",
        "\treturn boxes\n",
        "\n",
        "def random_distort_image(image, hue=18, saturation=1.5, exposure=1.5):\n",
        "\tdhue = np.random.uniform(-hue, hue)\n",
        "\tdsat = _rand_scale(saturation);\n",
        "\tdexp = _rand_scale(exposure);\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype('float')\n",
        "\timage[:,:,1] *= dsat\n",
        "\timage[:,:,2] *= dexp\n",
        "\timage[:,:,0] += dhue\n",
        "\timage[:,:,0] -= (image[:,:,0] > 180)*180\n",
        "\timage[:,:,0] += (image[:,:,0] < 0)  *180\n",
        "\treturn cv2.cvtColor(image.astype('uint8'), cv2.COLOR_HSV2RGB)\n",
        "\n",
        "def apply_random_scale_and_crop(image, new_w, new_h, net_w, net_h, dx, dy):\n",
        "\tim_sized = cv2.resize(image, (new_w, new_h))\n",
        "\tif dx > 0:\n",
        "\t\tim_sized = np.pad(im_sized, ((0,0), (dx,0), (0,0)), mode='constant', constant_values=127)\n",
        "\telse:\n",
        "\t\tim_sized = im_sized[:,-dx:,:]\n",
        "\tif (new_w + dx) < net_w:\n",
        "\t\tim_sized = np.pad(im_sized, ((0,0), (0, net_w - (new_w+dx)), (0,0)), mode='constant', constant_values=127)\n",
        "\tif dy > 0:\n",
        "\t\tim_sized = np.pad(im_sized, ((dy,0), (0,0), (0,0)), mode='constant', constant_values=127)\n",
        "\telse:\n",
        "\t\tim_sized = im_sized[-dy:,:,:]\n",
        "\tif (new_h + dy) < net_h:\n",
        "\t\tim_sized = np.pad(im_sized, ((0, net_h - (new_h+dy)), (0,0), (0,0)), mode='constant', constant_values=127)\n",
        "\treturn im_sized[:net_h, :net_w,:]\n",
        "\n",
        "def _conv_block(inp, convs, do_skip=True):\n",
        "\tx = inp\n",
        "\tcount = 0\n",
        "\tfor conv in convs:\n",
        "\t\tif count == (len(convs) - 2) and do_skip:\n",
        "\t\t\tskip_connection = x\n",
        "\t\tcount += 1\n",
        "\t\tif conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x)\n",
        "\t\tx = Conv2D(conv['filter'],\n",
        "\t\t\t\t\tconv['kernel'],\n",
        "\t\t\t\t\tstrides=conv['stride'],\n",
        "\t\t\t\t\tpadding='valid' if conv['stride'] > 1 else 'same',\n",
        "\t\t\t\t\tname='conv_' + str(conv['layer_idx']),\n",
        "\t\t\t\t\tuse_bias=False if conv['bnorm'] else True)(x)\n",
        "\t\tif conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "\t\tif conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "\treturn add([skip_connection, x]) if do_skip else x\n",
        "\n",
        "def create_yolov3_model(nb_class, anchors, max_box_per_image, max_grid, batch_size, warmup_batches, ignore_thresh, grid_scales, obj_scale, noobj_scale, xywh_scale, class_scale):\n",
        "\tinput_image     = Input(shape=(None, None, 3))\n",
        "\ttrue_boxes      = Input(shape=(1, 1, 1, max_box_per_image, 4))\n",
        "\ttrue_yolo_1     = Input(shape=(None, None, len(anchors)//6, 4+1+nb_class))\n",
        "\ttrue_yolo_2     = Input(shape=(None, None, len(anchors)//6, 4+1+nb_class))\n",
        "\ttrue_yolo_3     = Input(shape=(None, None, len(anchors)//6, 4+1+nb_class))\n",
        "\tx = _conv_block(input_image, [\t{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "\tx = _conv_block(x, [\t\t\t{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "\t\t\t\t\t\t\t\t\t{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "\tx = _conv_block(x, [\t\t\t{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "\tx = _conv_block(x, [\t\t\t{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "\tfor i in range(7):\n",
        "\t\tx = _conv_block(x, [\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "\tskip_36 = x\n",
        "\tx = _conv_block(x, [\t\t\t{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "\tfor i in range(7):\n",
        "\t\tx = _conv_block(x, [\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "\tskip_61 = x\n",
        "\tx = _conv_block(x, [\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "\t\t\t\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "\tfor i in range(3):\n",
        "\t\tx = _conv_block(x, [\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "\tx = _conv_block(x, [\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "\t\t\t\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "\t\t\t\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], do_skip=False)\n",
        "\tpred_yolo_1 = _conv_block(x, [\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': (3*(5+nb_class)), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], do_skip=False)\n",
        "\tloss_yolo_1 = YoloLayer(anchors[12:], [1*num for num in max_grid], batch_size, warmup_batches, ignore_thresh, grid_scales[0], obj_scale, noobj_scale, xywh_scale, class_scale)([input_image, pred_yolo_1, true_yolo_1, true_boxes])\n",
        "\tx = _conv_block(x, [\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], do_skip=False)\n",
        "\tx = UpSampling2D(2)(x)\n",
        "\tx = concatenate([x, skip_61])\n",
        "\tx = _conv_block(x, [\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], do_skip=False)\n",
        "\tpred_yolo_2 = _conv_block(x, [\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': (3*(5+nb_class)), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], do_skip=False)\n",
        "\tloss_yolo_2 = YoloLayer(anchors[6:12], [2*num for num in max_grid], batch_size, warmup_batches, ignore_thresh, grid_scales[1], obj_scale, noobj_scale, xywh_scale, class_scale)([input_image, pred_yolo_2, true_yolo_2, true_boxes])\n",
        "\tx = _conv_block(x, [\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], do_skip=False)\n",
        "\tx = UpSampling2D(2)(x)\n",
        "\tx = concatenate([x, skip_36])\n",
        "\tpred_yolo_3 = _conv_block(x, [\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "\t\t\t\t\t\t\t\t\t{'filter': (3*(5+nb_class)), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], do_skip=False)\n",
        "\tloss_yolo_3 = YoloLayer(anchors[:6], [4*num for num in max_grid], batch_size, warmup_batches, ignore_thresh, grid_scales[2], obj_scale, noobj_scale, xywh_scale, class_scale)([input_image, pred_yolo_3, true_yolo_3, true_boxes])\n",
        "\ttrain_model = Model([input_image, true_boxes, true_yolo_1, true_yolo_2, true_yolo_3], [loss_yolo_1, loss_yolo_2, loss_yolo_3])\n",
        "\tinfer_model = Model(input_image, [pred_yolo_1, pred_yolo_2, pred_yolo_3])\n",
        "\treturn [train_model, infer_model]\n",
        "\n",
        "def dummy_loss(y_true, y_pred):\n",
        "\treturn tf.sqrt(tf.reduce_sum(y_pred))\n",
        "\n",
        "def multi_gpu_model(model, gpus):\n",
        "\tif isinstance(gpus, (list, tuple)):\n",
        "\t\tnum_gpus = len(gpus)\n",
        "\t\ttarget_gpu_ids = gpus\n",
        "\telse:\n",
        "\t\tnum_gpus = gpus\n",
        "\t\ttarget_gpu_ids = range(num_gpus)\n",
        "\tdef get_slice(data, i, parts):\n",
        "\t\tshape = tf.shape(data)\n",
        "\t\tbatch_size = shape[:1]\n",
        "\t\tinput_shape = shape[1:]\n",
        "\t\tstep = batch_size // parts\n",
        "\t\tif i == num_gpus - 1:\n",
        "\t\t\tsize = batch_size - step * i\n",
        "\t\telse:\n",
        "\t\t\tsize = step\n",
        "\t\tsize = tf.concat([size, input_shape], axis=0)\n",
        "\t\tstride = tf.concat([step, input_shape * 0], axis=0)\n",
        "\t\tstart = stride * i\n",
        "\t\treturn tf.slice(data, start, size)\n",
        "\tall_outputs = []\n",
        "\tfor i in range(len(model.outputs)):\n",
        "\t\tall_outputs.append([])\n",
        "\tfor i, gpu_id in enumerate(target_gpu_ids):\n",
        "\t\twith tf.device('/gpu:%d' % gpu_id):\n",
        "\t\t\twith tf.name_scope('replica_%d' % gpu_id):\n",
        "\t\t\t\tinputs = []\n",
        "\t\t\t\tfor x in model.inputs:\n",
        "\t\t\t\t\tinput_shape = tuple(x.get_shape().as_list())[1:]\n",
        "\t\t\t\t\tslice_i = Lambda(get_slice, output_shape=input_shape, arguments={'i': i, 'parts': num_gpus})(x)\n",
        "\t\t\t\t\tinputs.append(slice_i)\n",
        "\t\t\t\toutputs = model(inputs)\n",
        "\t\t\t\tif not isinstance(outputs, list):\n",
        "\t\t\t\t\toutputs = [outputs]\n",
        "\t\t\t\tfor o in range(len(outputs)):\n",
        "\t\t\t\t\tall_outputs[o].append(outputs[o])\n",
        "\twith tf.device('/cpu:0'):\n",
        "\t\tmerged = []\n",
        "\t\tfor name, outputs in zip(model.output_names, all_outputs):\n",
        "\t\t\tmerged.append(concatenate(outputs, axis=0, name=name))\n",
        "\t\treturn Model(model.inputs, merged)\n",
        "\n",
        "def get_color(label):\n",
        "\tif label < len(colors):\n",
        "\t\treturn colors[label]\n",
        "\telse:\n",
        "\t\tprint('Label {} has no color, returning default.'.format(label))\n",
        "\t\treturn (0, 255, 0)\n",
        "\n",
        "colors = \t[[31 , 0   , 255] ,\n",
        "\t\t\t[0   , 159 , 255] ,\n",
        "\t\t\t[255 , 95  , 0]   ,\n",
        "\t\t\t[255 , 19  , 0]   ,\n",
        "\t\t\t[255 , 0   , 0]   ,\n",
        "\t\t\t[255 , 38  , 0]   ,\n",
        "\t\t\t[0   , 255 , 25]  ,\n",
        "\t\t\t[255 , 0   , 133] ,\n",
        "\t\t\t[255 , 172 , 0]   ,\n",
        "\t\t\t[108 , 0   , 255] ,\n",
        "\t\t\t[0   , 82  , 255] ,\n",
        "\t\t\t[0   , 255 , 6]   ,\n",
        "\t\t\t[255 , 0   , 152] ,\n",
        "\t\t\t[223 , 0   , 255] ,\n",
        "\t\t\t[12  , 0   , 255] ,\n",
        "\t\t\t[0   , 255 , 178] ,\n",
        "\t\t\t[108 , 255 , 0]   ,\n",
        "\t\t\t[184 , 0   , 255] ,\n",
        "\t\t\t[255 , 0   , 76]  ,\n",
        "\t\t\t[146 , 255 , 0]   ,\n",
        "\t\t\t[51  , 0   , 255] ,\n",
        "\t\t\t[0   , 197 , 255] ,\n",
        "\t\t\t[255 , 248 , 0]   ,\n",
        "\t\t\t[255 , 0   , 19]  ,\n",
        "\t\t\t[255 , 0   , 38]  ,\n",
        "\t\t\t[89  , 255 , 0]   ,\n",
        "\t\t\t[127 , 255 , 0]   ,\n",
        "\t\t\t[255 , 153 , 0]   ,\n",
        "\t\t\t[0   , 255 , 255] ,\n",
        "\t\t\t[0   , 255 , 216] ,\n",
        "\t\t\t[0   , 255 , 121] ,\n",
        "\t\t\t[255 , 0   , 248] ,\n",
        "\t\t\t[70  , 0   , 255] ,\n",
        "\t\t\t[0   , 255 , 159] ,\n",
        "\t\t\t[0   , 216 , 255] ,\n",
        "\t\t\t[0   , 6   , 255] ,\n",
        "\t\t\t[0   , 63  , 255] ,\n",
        "\t\t\t[31  , 255 , 0]   ,\n",
        "\t\t\t[255 , 57  , 0]   ,\n",
        "\t\t\t[255 , 0   , 210] ,\n",
        "\t\t\t[0   , 255 , 102] ,\n",
        "\t\t\t[242 , 255 , 0]   ,\n",
        "\t\t\t[255 , 191 , 0]   ,\n",
        "\t\t\t[0   , 255 , 63]  ,\n",
        "\t\t\t[255 , 0   , 95]  ,\n",
        "\t\t\t[146 , 0   , 255] ,\n",
        "\t\t\t[184 , 255 , 0]   ,\n",
        "\t\t\t[255 , 114 , 0]   ,\n",
        "\t\t\t[0   , 255 , 235] ,\n",
        "\t\t\t[255 , 229 , 0]   ,\n",
        "\t\t\t[0   , 178 , 255] ,\n",
        "\t\t\t[255 , 0   , 114] ,\n",
        "\t\t\t[255 , 0   , 57]  ,\n",
        "\t\t\t[0   , 140 , 255] ,\n",
        "\t\t\t[0   , 121 , 255] ,\n",
        "\t\t\t[12  , 255 , 0]   ,\n",
        "\t\t\t[255 , 210 , 0]   ,\n",
        "\t\t\t[0   , 255 , 44]  ,\n",
        "\t\t\t[165 , 255 , 0]   ,\n",
        "\t\t\t[0   , 25  , 255] ,\n",
        "\t\t\t[0   , 255 , 140] ,\n",
        "\t\t\t[0   , 101 , 255] ,\n",
        "\t\t\t[0   , 255 , 82]  ,\n",
        "\t\t\t[223 , 255 , 0]   ,\n",
        "\t\t\t[242 , 0   , 255] ,\n",
        "\t\t\t[89  , 0   , 255] ,\n",
        "\t\t\t[165 , 0   , 255] ,\n",
        "\t\t\t[70  , 255 , 0]   ,\n",
        "\t\t\t[255 , 0   , 172] ,\n",
        "\t\t\t[255 , 76  , 0]   ,\n",
        "\t\t\t[203 , 255 , 0]   ,\n",
        "\t\t\t[204 , 0   , 255] ,\n",
        "\t\t\t[255 , 0   , 229] ,\n",
        "\t\t\t[255 , 133 , 0]   ,\n",
        "\t\t\t[127 , 0   , 255] ,\n",
        "\t\t\t[0   , 235 , 255] ,\n",
        "\t\t\t[0   , 255 , 197] ,\n",
        "\t\t\t[255 , 0   , 191] ,\n",
        "\t\t\t[0   , 44  , 255] ,\n",
        "\t\t\t[50  , 255 , 0]]\n",
        "\n",
        "class BoundBox:\n",
        "\tdef __init__(self, xmin, ymin, xmax, ymax, c = None, classes = None):\n",
        "\t\tself.xmin = xmin\n",
        "\t\tself.ymin = ymin\n",
        "\t\tself.xmax = xmax\n",
        "\t\tself.ymax = ymax\n",
        "\t\tself.c    = c\n",
        "\t\tself.classes = classes\n",
        "\t\tself.label = -1\n",
        "\t\tself.score = -1\n",
        "\tdef get_label(self):\n",
        "\t\tif self.label == -1:\n",
        "\t\t\tself.label = np.argmax(self.classes)\n",
        "\t\tprint(self.xmin, self.ymin, self.xmax, self.ymax, config['model']['labels'][self.label])\n",
        "\t\treturn self.label\n",
        "\tdef get_score(self):\n",
        "\t\tif self.score == -1:\n",
        "\t\t\tself.score = self.classes[self.get_label()]\n",
        "\t\treturn self.score\n",
        "\n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "\tx1, x2 = interval_a\n",
        "\tx3, x4 = interval_b\n",
        "\tif x3 < x1:\n",
        "\t\tif x4 < x1: return 0\n",
        "\t\telse: return min(x2,x4) - x1\n",
        "\telse:\n",
        "\t\tif x2 < x3: return 0\n",
        "\t\telse: return min(x2,x4) - x3\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "\tintersect = intersect_w * intersect_h\n",
        "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\tunion = w1*h1 + w2*h2 - intersect\n",
        "\treturn float(intersect) / union\n",
        "\n",
        "def draw_boxes(image, boxes, labels, obj_thresh, quiet=True):\n",
        "\tfor box in boxes:\n",
        "\t\tlabel_str = ''\n",
        "\t\tlabel = -1\n",
        "\t\tfor i in range(len(labels)):\n",
        "\t\t\tif box.classes[i] > obj_thresh:\n",
        "\t\t\t\tif label_str != '': label_str += ', '\n",
        "\t\t\t\tlabel_str += (labels[i] + ' ' + str(round(box.get_score()*100, 2)) + '%')\n",
        "\t\t\t\tlabel = i\n",
        "\t\t\tif not quiet: print(label_str)\n",
        "\t\tif label >= 0:\n",
        "\t\t\ttext_size = cv2.getTextSize(label_str, cv2.FONT_HERSHEY_SIMPLEX, 1.1e-3 * image.shape[0], 5)\n",
        "\t\t\twidth, height = text_size[0][0], text_size[0][1]\n",
        "\t\t\tregion = np.array([[box.xmin-3, box.ymin], [box.xmin-3, box.ymin-height-26], [box.xmin+width+13, box.ymin-height-26], [box.xmin+width+13, box.ymin]], dtype='int32')\n",
        "\t\t\tcv2.rectangle(img=image, pt1=(box.xmin,box.ymin), pt2=(box.xmax,box.ymax), color=get_color(label), thickness=3)\n",
        "\t\t\tcv2.fillPoly(img=image, pts=[region], color=get_color(label))\n",
        "\t\t\tcv2.putText(img=image, text=label_str, org=(box.xmin+13, box.ymin - 13), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1e-3 * image.shape[0], color=(0,0,0), thickness=2)\n",
        "\treturn image\n",
        "\n",
        "def _sigmoid(x):\n",
        "\treturn scipy.special.expit(x)\n",
        " \n",
        "def makedirs(path):\n",
        "\ttry:\n",
        "\t\tos.makedirs(path)\n",
        "\texcept OSError:\n",
        "\t\tif not os.path.isdir(path):\n",
        "\t\t\traise\n",
        "\n",
        "def evaluate(model, generator, iou_threshold=0.5, obj_thresh=0.5, nms_thresh=0.45, net_h=416, net_w=416, save_path=None):\n",
        "\tall_detections      = [[None for i in range(generator.num_classes())] for j in range(generator.size())]\n",
        "\tall_annotations     = [[None for i in range(generator.num_classes())] for j in range(generator.size())]\n",
        "\tfor i in range(generator.size()):\n",
        "\t\traw_image = [generator.load_image(i)]\n",
        "\t\tpred_boxes = get_yolo_boxes(model, raw_image, net_h, net_w, generator.get_anchors(), obj_thresh, nms_thresh)[0]\n",
        "\t\tscore = np.array([box.get_score() for box in pred_boxes])\n",
        "\t\tpred_labels = np.array([box.label for box in pred_boxes])\n",
        "\t\tif len(pred_boxes) > 0:\n",
        "\t\t\tpred_boxes = np.array([[box.xmin, box.ymin, box.xmax, box.ymax, box.get_score()] for box in pred_boxes]) \n",
        "\t\telse:\n",
        "\t\t\tpred_boxes = np.array([[]])\n",
        "\t\tscore_sort  = np.argsort(-score)\n",
        "\t\tpred_labels = pred_labels[score_sort]\n",
        "\t\tpred_boxes  = pred_boxes[score_sort]\n",
        "\t\tfor label in range(generator.num_classes()):\n",
        "\t\t\tall_detections[i][label] = pred_boxes[pred_labels == label, :]\n",
        "\t\tannotations = generator.load_annotation(i)\n",
        "\t\tfor label in range(generator.num_classes()):\n",
        "\t\t\tall_annotations[i][label] = annotations[annotations[:, 4] == label, :4].copy()\n",
        "\taverage_precisions = {}\n",
        "\tfor label in range(generator.num_classes()):\n",
        "\t\tfalse_positives = np.zeros((0,))\n",
        "\t\ttrue_positives  = np.zeros((0,))\n",
        "\t\tscores          = np.zeros((0,))\n",
        "\t\tnum_annotations = 0.0\n",
        "\t\tfor i in range(generator.size()):\n",
        "\t\t\tdetections              = all_detections[i][label]\n",
        "\t\t\tannotations             = all_annotations[i][label]\n",
        "\t\t\tnum_annotations        += annotations.shape[0]\n",
        "\t\t\tdetected_annotations    = []\n",
        "\t\t\tfor d in detections:\n",
        "\t\t\t\tscores = np.append(scores, d[4])\n",
        "\t\t\t\tif annotations.shape[0] == 0:\n",
        "\t\t\t\t\tfalse_positives = np.append(false_positives, 1)\n",
        "\t\t\t\t\ttrue_positives  = np.append(true_positives, 0)\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\toverlaps            = compute_overlap(np.expand_dims(d, axis=0), annotations)\n",
        "\t\t\t\tassigned_annotation = np.argmax(overlaps, axis=1)\n",
        "\t\t\t\tmax_overlap         = overlaps[0, assigned_annotation]\n",
        "\t\t\t\tif max_overlap >= iou_threshold and assigned_annotation not in detected_annotations:\n",
        "\t\t\t\t\tfalse_positives = np.append(false_positives, 0)\n",
        "\t\t\t\t\ttrue_positives  = np.append(true_positives, 1)\n",
        "\t\t\t\t\tdetected_annotations.append(assigned_annotation)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tfalse_positives = np.append(false_positives, 1)\n",
        "\t\t\t\t\ttrue_positives  = np.append(true_positives, 0)\n",
        "\t\tif num_annotations == 0:\n",
        "\t\t\taverage_precisions[label] = 0\n",
        "\t\t\tcontinue\n",
        "\t\tindices         = np.argsort(-scores)\n",
        "\t\tfalse_positives = false_positives[indices]\n",
        "\t\ttrue_positives  = true_positives[indices]\n",
        "\t\tfalse_positives = np.cumsum(false_positives)\n",
        "\t\ttrue_positives  = np.cumsum(true_positives)\n",
        "\t\trecall          = true_positives / num_annotations\n",
        "\t\tprecision       = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
        "\t\taverage_precision           = compute_ap(recall, precision)\n",
        "\t\taverage_precisions[label]   = average_precision\n",
        "\treturn average_precisions\n",
        "\n",
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "\tif (float(net_w)/image_w) < (float(net_h)/image_h):\n",
        "\t\tnew_w = net_w\n",
        "\t\tnew_h = (image_h*net_w)/image_w\n",
        "\telse:\n",
        "\t\tnew_h = net_w\n",
        "\t\tnew_w = (image_w*net_h)/image_h\n",
        "\tfor i in range(len(boxes)):\n",
        "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
        "\n",
        "def do_nms(boxes, nms_thresh):\n",
        "\tif len(boxes) > 0:\n",
        "\t\tnb_class = len(boxes[0].classes)\n",
        "\telse:\n",
        "\t\treturn\n",
        "\tfor c in range(nb_class):\n",
        "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\t\tfor i in range(len(sorted_indices)):\n",
        "\t\t\tindex_i = sorted_indices[i]\n",
        "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
        "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
        "\t\t\t\tindex_j = sorted_indices[j]\n",
        "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "\t\t\t\t\tboxes[index_j].classes[c] = 0\n",
        "\n",
        "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
        "\tgrid_h, grid_w = netout.shape[:2]\n",
        "\tnb_box = 3\n",
        "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "\tnb_class = netout.shape[-1] - 5\n",
        "\tboxes = []\n",
        "\tnetout[..., :2]     = _sigmoid(netout[..., :2])\n",
        "\tnetout[..., 4]      = _sigmoid(netout[..., 4])\n",
        "\tnetout[..., 5:]     = netout[..., 4][..., np.newaxis] * _softmax(netout[..., 5:])\n",
        "\tnetout[..., 5:]    *= netout[..., 5:] > obj_thresh\n",
        "\tfor i in range(grid_h*grid_w):\n",
        "\t\trow = i // grid_w\n",
        "\t\tcol = i % grid_w\n",
        "\t\tfor b in range(nb_box):\n",
        "\t\t\tobjectness = netout[row, col, b, 4]\n",
        "\t\t\tif(objectness <= obj_thresh): continue\n",
        "\t\t\tx, y, w, h = netout[row,col,b,:4]\n",
        "\t\t\tx = (col + x) / grid_w\n",
        "\t\t\ty = (row + y) / grid_h\n",
        "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w\n",
        "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h\n",
        "\t\t\tclasses = netout[row,col,b,5:]\n",
        "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "\t\t\tboxes.append(box)\n",
        "\treturn boxes\n",
        "\n",
        "def preprocess_input(image, net_h, net_w):\n",
        "\tnew_h, new_w, _ = image.shape\n",
        "\tif (float(net_w)/new_w) < (float(net_h)/new_h):\n",
        "\t\tnew_h = (new_h * net_w)//new_w\n",
        "\t\tnew_w = net_w\n",
        "\telse:\n",
        "\t\tnew_w = (new_w * net_h)//new_h\n",
        "\t\tnew_h = net_h\n",
        "\tresized = cv2.resize(image[:,:,::-1]/255., (new_w, new_h))\n",
        "\tnew_image = np.ones((net_h, net_w, 3)) * 0.5\n",
        "\tnew_image[(net_h-new_h)//2:(net_h+new_h)//2, (net_w-new_w)//2:(net_w+new_w)//2, :] = resized\n",
        "\tnew_image = np.expand_dims(new_image, 0)\n",
        "\treturn new_image\n",
        "\n",
        "def normalize(image):\n",
        "\treturn image/255.\n",
        "\n",
        "def get_yolo_boxes(model, images, net_h, net_w, anchors, obj_thresh, nms_thresh):\n",
        "\timage_h, image_w, _ = images[0].shape\n",
        "\tnb_images           = len(images)\n",
        "\tbatch_input         = np.zeros((nb_images, net_h, net_w, 3))\n",
        "\tfor i in range(nb_images):\n",
        "\t\tbatch_input[i] = preprocess_input(images[i], net_h, net_w)\n",
        "\tbatch_output = model.predict_on_batch(batch_input)\n",
        "\tbatch_boxes  = [None]*nb_images\n",
        "\tfor i in range(nb_images):\n",
        "\t\tyolos = [batch_output[0][i], batch_output[1][i], batch_output[2][i]]\n",
        "\t\tboxes = []\n",
        "\t\tfor j in range(len(yolos)):\n",
        "\t\t\tyolo_anchors = anchors[(2-j)*6:(3-j)*6]\n",
        "\t\t\tboxes += decode_netout(yolos[j], yolo_anchors, obj_thresh, net_h, net_w)\n",
        "\t\tcorrect_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n",
        "\t\tdo_nms(boxes, nms_thresh)\n",
        "\t\tbatch_boxes[i] = boxes\n",
        "\treturn batch_boxes\n",
        "\n",
        "def compute_overlap(a, b):\n",
        "\tarea = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
        "\tiw = np.minimum(np.expand_dims(a[:, 2], axis=1), b[:, 2]) - np.maximum(np.expand_dims(a[:, 0], 1), b[:, 0])\n",
        "\tih = np.minimum(np.expand_dims(a[:, 3], axis=1), b[:, 3]) - np.maximum(np.expand_dims(a[:, 1], 1), b[:, 1])\n",
        "\tiw = np.maximum(iw, 0)\n",
        "\tih = np.maximum(ih, 0)\n",
        "\tua = np.expand_dims((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), axis=1) + area - iw * ih\n",
        "\tua = np.maximum(ua, np.finfo(float).eps)\n",
        "\tintersection = iw * ih\n",
        "\treturn intersection / ua\n",
        "\n",
        "def compute_ap(recall, precision):\n",
        "\tmrec = np.concatenate(([0.], recall, [1.]))\n",
        "\tmpre = np.concatenate(([0.], precision, [0.]))\n",
        "\tfor i in range(mpre.size - 1, 0, -1):\n",
        "\t\tmpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
        "\ti = np.where(mrec[1:] != mrec[:-1])[0]\n",
        "\tap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
        "\treturn ap\n",
        "\n",
        "def _softmax(x, axis=-1):\n",
        "\tx = x - np.amax(x, axis, keepdims=True)\n",
        "\te_x = np.exp(x)\n",
        "\treturn e_x / e_x.sum(axis, keepdims=True)\n",
        "\n",
        "class BatchGenerator(Sequence):\n",
        "\tdef __init__(self,\n",
        "\t\tinstances,\n",
        "\t\tanchors,\n",
        "\t\tlabels,\n",
        "\t\tdownsample=32,\n",
        "\t\tmax_box_per_image=30,\n",
        "\t\tbatch_size=1,\n",
        "\t\tmin_net_size=320,\n",
        "\t\tmax_net_size=608,\n",
        "\t\tshuffle=True,\n",
        "\t\tjitter=True,\n",
        "\t\tnorm=None):\n",
        "\t\tself.instances          = instances\n",
        "\t\tself.batch_size         = batch_size\n",
        "\t\tself.labels             = labels\n",
        "\t\tself.downsample         = downsample\n",
        "\t\tself.max_box_per_image  = max_box_per_image\n",
        "\t\tself.min_net_size       = (min_net_size // self.downsample) * self.downsample\n",
        "\t\tself.max_net_size       = (max_net_size // self.downsample) * self.downsample\n",
        "\t\tself.shuffle            = shuffle\n",
        "\t\tself.jitter             = jitter\n",
        "\t\tself.norm               = norm\n",
        "\t\tself.anchors            = [BoundBox(0, 0, anchors[2*i], anchors[2*i+1]) for i in range(len(anchors)//2)]\n",
        "\t\tself.net_h              = 416\n",
        "\t\tself.net_w              = 416\n",
        "\t\tif shuffle: np.random.shuffle(self.instances)\n",
        "\tdef __len__(self):\n",
        "\t\treturn int(np.ceil(float(len(self.instances))/self.batch_size))\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\tnet_h, net_w = self._get_net_size(idx)\n",
        "\t\tbase_grid_h, base_grid_w = net_h//self.downsample, net_w//self.downsample\n",
        "\t\tl_bound = idx*self.batch_size\n",
        "\t\tr_bound = (idx+1)*self.batch_size\n",
        "\t\tif r_bound > len(self.instances):\n",
        "\t\t\tr_bound = len(self.instances)\n",
        "\t\t\tl_bound = r_bound - self.batch_size\n",
        "\t\tx_batch = np.zeros((r_bound - l_bound, net_h, net_w, 3))\n",
        "\t\tt_batch = np.zeros((r_bound - l_bound, 1, 1, 1, self.max_box_per_image, 4))\n",
        "\t\tyolo_1 = np.zeros((r_bound - l_bound, 1*base_grid_h, 1*base_grid_w, len(self.anchors)//3, 4+1+len(self.labels)))\n",
        "\t\tyolo_2 = np.zeros((r_bound - l_bound, 2*base_grid_h, 2*base_grid_w, len(self.anchors)//3, 4+1+len(self.labels)))\n",
        "\t\tyolo_3 = np.zeros((r_bound - l_bound, 4*base_grid_h, 4*base_grid_w, len(self.anchors)//3, 4+1+len(self.labels)))\n",
        "\t\tyolos = [yolo_3, yolo_2, yolo_1]\n",
        "\t\tdummy_yolo_1 = np.zeros((r_bound - l_bound, 1))\n",
        "\t\tdummy_yolo_2 = np.zeros((r_bound - l_bound, 1))\n",
        "\t\tdummy_yolo_3 = np.zeros((r_bound - l_bound, 1))\n",
        "\t\tinstance_count = 0\n",
        "\t\ttrue_box_index = 0\n",
        "\t\tfor train_instance in self.instances[l_bound:r_bound]:\n",
        "\t\t\timg, all_objs = self._aug_image(train_instance, net_h, net_w)\n",
        "\t\t\tfor obj in all_objs:\n",
        "\t\t\t\tmax_anchor  = None\n",
        "\t\t\t\tmax_index   = -1\n",
        "\t\t\t\tmax_iou     = -1\n",
        "\t\t\t\tshifted_box = BoundBox(0, 0, obj['xmax']-obj['xmin'], obj['ymax']-obj['ymin'])\n",
        "\t\t\t\tfor i in range(len(self.anchors)):\n",
        "\t\t\t\t\tanchor  = self.anchors[i]\n",
        "\t\t\t\t\tiou     = bbox_iou(shifted_box, anchor)\n",
        "\t\t\t\t\tif max_iou < iou:\n",
        "\t\t\t\t\t\tmax_anchor  = anchor\n",
        "\t\t\t\t\t\tmax_index   = i\n",
        "\t\t\t\t\t\tmax_iou     = iou\n",
        "\t\t\t\tyolo = yolos[max_index//3]\n",
        "\t\t\t\tgrid_h, grid_w = yolo.shape[1:3]\n",
        "\t\t\t\tcenter_x = .5*(obj['xmin'] + obj['xmax'])\n",
        "\t\t\t\tcenter_x = center_x / float(net_w) * grid_w\n",
        "\t\t\t\tcenter_y = .5*(obj['ymin'] + obj['ymax'])\n",
        "\t\t\t\tcenter_y = center_y / float(net_h) * grid_h\n",
        "\t\t\t\tw = np.log((obj['xmax'] - obj['xmin']) / float(max_anchor.xmax))\n",
        "\t\t\t\th = np.log((obj['ymax'] - obj['ymin']) / float(max_anchor.ymax))\n",
        "\t\t\t\tbox = [center_x, center_y, w, h]\n",
        "\t\t\t\tobj_indx = self.labels.index(obj['name'])\n",
        "\t\t\t\tgrid_x = int(np.floor(center_x))\n",
        "\t\t\t\tgrid_y = int(np.floor(center_y))\n",
        "\t\t\t\tyolo[instance_count, grid_y, grid_x, max_index%3]      = 0\n",
        "\t\t\t\tyolo[instance_count, grid_y, grid_x, max_index%3, 0:4] = box\n",
        "\t\t\t\tyolo[instance_count, grid_y, grid_x, max_index%3, 4  ] = 1.\n",
        "\t\t\t\tyolo[instance_count, grid_y, grid_x, max_index%3, 5+obj_indx] = 1\n",
        "\t\t\t\ttrue_box = [center_x, center_y, obj['xmax'] - obj['xmin'], obj['ymax'] - obj['ymin']]\n",
        "\t\t\t\tt_batch[instance_count, 0, 0, 0, true_box_index] = true_box\n",
        "\t\t\t\ttrue_box_index += 1\n",
        "\t\t\t\ttrue_box_index = true_box_index % self.max_box_per_image\n",
        "\t\t\tif self.norm != None:\n",
        "\t\t\t\tx_batch[instance_count] = self.norm(img)\n",
        "\t\t\telse:\n",
        "\t\t\t\tfor obj in all_objs:\n",
        "\t\t\t\t\tcv2.rectangle(img, (obj['xmin'],obj['ymin']), (obj['xmax'],obj['ymax']), (255,0,0), 3)\n",
        "\t\t\t\t\tcv2.putText(img, obj['name'], (obj['xmin']+2, obj['ymin']+12), 0, 1.2e-3 * img.shape[0], (0,255,0), 2)\n",
        "\t\t\t\tx_batch[instance_count] = img\n",
        "\t\t\tinstance_count += 1\n",
        "\t\treturn [x_batch, t_batch, yolo_1, yolo_2, yolo_3], [dummy_yolo_1, dummy_yolo_2, dummy_yolo_3]\n",
        "\tdef _get_net_size(self, idx):\n",
        "\t\tif idx%10 == 0:\n",
        "\t\t\tnet_size = self.downsample*np.random.randint(self.min_net_size/self.downsample, self.max_net_size/self.downsample+1)\n",
        "\t\t\tprint('resizing: ', net_size, net_size)\n",
        "\t\t\tself.net_h, self.net_w = net_size, net_size\n",
        "\t\treturn self.net_h, self.net_w\n",
        "\tdef _aug_image(self, instance, net_h, net_w):\n",
        "\t\timage_name = instance['filename']\n",
        "\t\timage = cv2.imread(image_name)\n",
        "\t\tif image is None: print('Cannot find ', image_name)\n",
        "\t\timage = image[:,:,::-1]\n",
        "\t\timage_h, image_w, _ = image.shape\n",
        "\t\tdw = self.jitter * image_w;\n",
        "\t\tdh = self.jitter * image_h;\n",
        "\t\tnew_ar = (image_w + np.random.uniform(-dw, dw)) / (image_h + np.random.uniform(-dh, dh));\n",
        "\t\tscale = np.random.uniform(0.25, 2);\n",
        "\t\tif (new_ar < 1):\n",
        "\t\t\tnew_h = int(scale * net_h);\n",
        "\t\t\tnew_w = int(net_h * new_ar);\n",
        "\t\telse:\n",
        "\t\t\tnew_w = int(scale * net_w);\n",
        "\t\t\tnew_h = int(net_w / new_ar);\n",
        "\t\tdx = int(np.random.uniform(0, net_w - new_w));\n",
        "\t\tdy = int(np.random.uniform(0, net_h - new_h));\n",
        "\t\tim_sized = apply_random_scale_and_crop(image, new_w, new_h, net_w, net_h, dx, dy)\n",
        "\t\tim_sized = random_distort_image(im_sized)\n",
        "\t\tflip = np.random.randint(2)\n",
        "\t\tim_sized = random_flip(im_sized, flip)\n",
        "\t\tall_objs = correct_bounding_boxes(instance['object'], new_w, new_h, net_w, net_h, dx, dy, flip, image_w, image_h)\n",
        "\t\treturn im_sized, all_objs\n",
        "\tdef on_epoch_end(self):\n",
        "\t\tif self.shuffle: np.random.shuffle(self.instances)\n",
        "\tdef num_classes(self):\n",
        "\t\treturn len(self.labels)\n",
        "\tdef size(self):\n",
        "\t\treturn len(self.instances)\n",
        "\tdef get_anchors(self):\n",
        "\t\tanchors = []\n",
        "\t\tfor anchor in self.anchors:\n",
        "\t\t\tanchors += [anchor.xmax, anchor.ymax]\n",
        "\t\treturn anchors\n",
        "\tdef load_annotation(self, i):\n",
        "\t\tannots = []\n",
        "\t\tfor obj in self.instances[i]['object']:\n",
        "\t\t\tannot = [obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax'], self.labels.index(obj['name'])]\n",
        "\t\t\tannots += [annot]\n",
        "\t\tif len(annots) == 0: annots = [[]]\n",
        "\t\treturn np.array(annots)\n",
        "\tdef load_image(self, i):\n",
        "\t\treturn cv2.imread(self.instances[i]['filename'])\n",
        "def parse_voc_annotation(ann_dir, img_dir, cache_name, labels=[]):\n",
        "\tif os.path.exists(cache_name):\n",
        "\t\twith open(cache_name, 'rb') as handle:\n",
        "\t\t\tcache = pickle.load(handle)\n",
        "\t\tall_insts, seen_labels = cache['all_insts'], cache['seen_labels']\n",
        "\telse:\n",
        "\t\tall_insts = []\n",
        "\t\tseen_labels = {}\n",
        "\t\tfor ann in sorted(os.listdir(ann_dir)):\n",
        "\t\t\timg = {'object':[]}\n",
        "\t\t\ttry:\n",
        "\t\t\t\ttree = ET.parse(ann_dir + ann)\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\tprint(e)\n",
        "\t\t\t\tprint('Ignore this bad annotation: ' + ann_dir + ann)\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tfor elem in tree.iter():\n",
        "\t\t\t\tif 'filename' in elem.tag:\n",
        "\t\t\t\t\timg['filename'] = img_dir + elem.text\n",
        "\t\t\t\tif 'width' in elem.tag:\n",
        "\t\t\t\t\timg['width'] = int(elem.text)\n",
        "\t\t\t\tif 'height' in elem.tag:\n",
        "\t\t\t\t\timg['height'] = int(elem.text)\n",
        "\t\t\t\tif 'object' in elem.tag or 'part' in elem.tag:\n",
        "\t\t\t\t\tobj = {}\n",
        "\t\t\t\t\tfor attr in list(elem):\n",
        "\t\t\t\t\t\tif 'name' in attr.tag:\n",
        "\t\t\t\t\t\t\tobj['name'] = attr.text\n",
        "\t\t\t\t\t\t\tif obj['name'] in seen_labels:\n",
        "\t\t\t\t\t\t\t\tseen_labels[obj['name']] += 1\n",
        "\t\t\t\t\t\t\telse: seen_labels[obj['name']] = 1\n",
        "\t\t\t\t\t\t\tif len(labels) > 0 and obj['name'] not in labels: break\n",
        "\t\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\t\timg['object'] += [obj]\n",
        "\t\t\t\t\t\tif 'bndbox' in attr.tag:\n",
        "\t\t\t\t\t\t\tfor dim in list(attr):\n",
        "\t\t\t\t\t\t\t\tif 'xmin' in dim.tag: obj['xmin'] = int(round(float(dim.text)))\n",
        "\t\t\t\t\t\t\t\tif 'ymin' in dim.tag: obj['ymin'] = int(round(float(dim.text)))\n",
        "\t\t\t\t\t\t\t\tif 'xmax' in dim.tag: obj['xmax'] = int(round(float(dim.text)))\n",
        "\t\t\t\t\t\t\t\tif 'ymax' in dim.tag: obj['ymax'] = int(round(float(dim.text)))\n",
        "\t\t\tif len(img['object']) > 0:\n",
        "\t\t\t\tall_insts += [img]\n",
        "\t\tcache = {'all_insts': all_insts, 'seen_labels': seen_labels}\n",
        "\t\twith open(cache_name, 'wb') as handle:\n",
        "\t\t\tpickle.dump(cache, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\treturn all_insts, seen_labels\n",
        "\n",
        "class CustomTensorBoard(TensorBoard):\n",
        "\t'''\n",
        "\tTo log the loss after each batch\n",
        "\t'''\n",
        "\tdef __init__(self, log_every=1, **kwargs):\n",
        "\t\tsuper(CustomTensorBoard, self).__init__(**kwargs)\n",
        "\t\tself.log_every = log_every\n",
        "\t\tself.counter = 0\n",
        "\tdef on_batch_end(self, batch, logs=None):\n",
        "\t\tself.counter+=1\n",
        "\t\tif self.counter%self.log_every==0:\n",
        "\t\t\tfor name, value in logs.items():\n",
        "\t\t\t\tif name in ['batch', 'size']:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tsummary = tf.Summary()\n",
        "\t\t\t\tsummary_value = summary.value.add()\n",
        "\t\t\t\tsummary_value.simple_value = value.item()\n",
        "\t\t\t\tsummary_value.tag = name\n",
        "\t\t\t\tself.writer.add_summary(summary, self.counter)\n",
        "\t\t\tself.writer.flush()\n",
        "\t\tsuper(CustomTensorBoard, self).on_batch_end(batch, logs)\n",
        "\n",
        "class CustomModelCheckpoint(ModelCheckpoint):\n",
        "\t'''\n",
        "\tTo save the template model, not the multi-GPU model\n",
        "\t'''\n",
        "\tdef __init__(self, model_to_save, **kwargs):\n",
        "\t\tsuper(CustomModelCheckpoint, self).__init__(**kwargs)\n",
        "\t\tself.model_to_save = model_to_save\n",
        "\tdef on_epoch_end(self, epoch, logs=None):\n",
        "\t\tlogs = logs or {}\n",
        "\t\tself.epochs_since_last_save += 1\n",
        "\t\tif self.epochs_since_last_save >= self.period:\n",
        "\t\t\tself.epochs_since_last_save = 0\n",
        "\t\t\tfilepath = self.filepath.format(epoch=epoch + 1, **logs)\n",
        "\t\t\tif self.save_best_only:\n",
        "\t\t\t\tcurrent = logs.get(self.monitor)\n",
        "\t\t\t\tif current is None:\n",
        "\t\t\t\t\twarnings.warn('Can save best model only with %s available, '\n",
        "\t\t\t\t\t\t\t\t\t'skipping.' % (self.monitor), RuntimeWarning)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tif self.monitor_op(current, self.best):\n",
        "\t\t\t\t\t\tif self.verbose > 0:\n",
        "\t\t\t\t\t\t\tprint('\\nEpoch %05d: %s improved from %0.5f to %0.5f,'\n",
        "\t\t\t\t\t\t\t\t\t' saving model to %s' % (epoch + 1, self.monitor, self.best, current, filepath))\n",
        "\t\t\t\t\t\tself.best = current\n",
        "\t\t\t\t\t\tif self.save_weights_only:\n",
        "\t\t\t\t\t\t\tself.model_to_save.save_weights(filepath, overwrite=True)\n",
        "\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\tself.model_to_save.save(filepath, overwrite=True)\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tif self.verbose > 0:\n",
        "\t\t\t\t\t\t\tprint('\\nEpoch %05d: %s did not improve from %0.5f' % (epoch + 1, self.monitor, self.best))\n",
        "\t\t\telse:\n",
        "\t\t\t\tif self.verbose > 0:\n",
        "\t\t\t\t\tprint('\\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))\n",
        "\t\t\t\tif self.save_weights_only:\n",
        "\t\t\t\t\tself.model_to_save.save_weights(filepath, overwrite=True)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tself.model_to_save.save(filepath, overwrite=True)\n",
        "\t\tsuper(CustomModelCheckpoint, self).on_batch_end(epoch, logs)\n",
        "\n",
        "def create_training_instances(train_annot_folder, train_image_folder, train_cache, valid_annot_folder, valid_image_folder, valid_cache, labels,):\n",
        "\ttrain_ints, train_labels = parse_voc_annotation(train_annot_folder, train_image_folder, train_cache, labels)\n",
        "\tprint('valid_annot_folder not exists. Spliting the trainining set.')\n",
        "\ttrain_valid_split = int(0.8*len(train_ints))\n",
        "\tnp.random.seed(0)\n",
        "\tnp.random.shuffle(train_ints)\n",
        "\tnp.random.seed()\n",
        "\tvalid_ints = train_ints[train_valid_split:]\n",
        "\ttrain_ints = train_ints[:train_valid_split]\n",
        "\tif len(labels) > 0:\n",
        "\t\toverlap_labels = set(labels).intersection(set(train_labels.keys()))\n",
        "\t\tprint('Seen labels: \\t'  + str(train_labels) + '\\n')\n",
        "\t\tprint('Given labels: \\t' + str(labels))\n",
        "\t\tif len(overlap_labels) < len(labels):\n",
        "\t\t\tprint('Some labels have no annotations! Please revise the list of labels in the config.json.')\n",
        "\t\t\treturn None, None, None\n",
        "\telse:\n",
        "\t\tprint('No labels are provided. Train on all seen labels.')\n",
        "\t\tprint(train_labels)\n",
        "\t\tlabels = train_labels.keys()\n",
        "\tmax_box_per_image = max([len(inst['object']) for inst in (train_ints + valid_ints)])\n",
        "\treturn train_ints, valid_ints, sorted(labels), max_box_per_image\n",
        "\n",
        "def create_callbacks(saved_weights_name, tensorboard_logs, model_to_save):\n",
        "\tmakedirs(tensorboard_logs)\n",
        "\tearly_stop = EarlyStopping(\n",
        "\t\tmonitor         = 'loss',\n",
        "\t\tmin_delta       = 0.01,\n",
        "\t\tpatience        = 5,\n",
        "\t\tmode            = 'min',\n",
        "\t\tverbose         = 1)\n",
        "\tcheckpoint = CustomModelCheckpoint(\n",
        "\t\tmodel_to_save   = model_to_save,\n",
        "\t\tfilepath        = saved_weights_name,\n",
        "\t\tmonitor         = 'loss',\n",
        "\t\tverbose         = 1,\n",
        "\t\tsave_best_only  = True,\n",
        "\t\tmode            = 'min',\n",
        "\t\tperiod          = 1)\n",
        "\treduce_on_plateau = ReduceLROnPlateau(\n",
        "\t\tmonitor         = 'loss',\n",
        "\t\tfactor          = .1,\n",
        "\t\tpatience        = 2,\n",
        "\t\tverbose         = 1,\n",
        "\t\tmode            = 'min',\n",
        "\t\tepsilon         = 0.01,\n",
        "\t\tcooldown        = 0,\n",
        "\t\tmin_lr          = 0)\n",
        "\ttensorboard = CustomTensorBoard(\n",
        "\t\tlog_dir         = tensorboard_logs,\n",
        "\t\twrite_graph     = True,\n",
        "\t\twrite_images    = True,)\n",
        "\treturn [early_stop, checkpoint, reduce_on_plateau, tensorboard]\n",
        "\n",
        "def create_model(\n",
        "\tnb_class,\n",
        "\tanchors,\n",
        "\tmax_box_per_image,\n",
        "\tmax_grid, batch_size,\n",
        "\twarmup_batches,\n",
        "\tignore_thresh,\n",
        "\tmulti_gpu,\n",
        "\tsaved_weights_name,\n",
        "\tlr,\n",
        "\tgrid_scales,\n",
        "\tobj_scale,\n",
        "\tnoobj_scale,\n",
        "\txywh_scale,\n",
        "\tclass_scale):\n",
        "\tif multi_gpu > 1:\n",
        "\t\twith tf.device('/cpu:0'):\n",
        "\t\t\ttemplate_model, infer_model = create_yolov3_model(\n",
        "\t\t\t\tnb_class            = nb_class,\n",
        "\t\t\t\tanchors             = anchors,\n",
        "\t\t\t\tmax_box_per_image   = max_box_per_image,\n",
        "\t\t\t\tmax_grid            = max_grid,\n",
        "\t\t\t\tbatch_size          = batch_size//multi_gpu,\n",
        "\t\t\t\twarmup_batches      = warmup_batches,\n",
        "\t\t\t\tignore_thresh       = ignore_thresh,\n",
        "\t\t\t\tgrid_scales         = grid_scales,\n",
        "\t\t\t\tobj_scale           = obj_scale,\n",
        "\t\t\t\tnoobj_scale         = noobj_scale,\n",
        "\t\t\t\txywh_scale          = xywh_scale,\n",
        "\t\t\t\tclass_scale         = class_scale)\n",
        "\telse:\n",
        "\t\ttemplate_model, infer_model = create_yolov3_model(\n",
        "\t\t\tnb_class                = nb_class,\n",
        "\t\t\tanchors                 = anchors,\n",
        "\t\t\tmax_box_per_image       = max_box_per_image,\n",
        "\t\t\tmax_grid                = max_grid,\n",
        "\t\t\tbatch_size              = batch_size,\n",
        "\t\t\twarmup_batches          = warmup_batches,\n",
        "\t\t\tignore_thresh           = ignore_thresh,\n",
        "\t\t\tgrid_scales             = grid_scales,\n",
        "\t\t\tobj_scale               = obj_scale,\n",
        "\t\t\tnoobj_scale             = noobj_scale,\n",
        "\t\t\txywh_scale              = xywh_scale,\n",
        "\t\t\tclass_scale             = class_scale)\n",
        "\tif os.path.exists(saved_weights_name):\n",
        "\t\tprint('\\nLoading pretrained weights.\\n')\n",
        "\t\ttemplate_model.load_weights(saved_weights_name)\n",
        "\tif multi_gpu > 1:\n",
        "\t\ttrain_model = multi_gpu_model(template_model, gpus=multi_gpu)\n",
        "\telse:\n",
        "\t\ttrain_model = template_model\n",
        "\toptimizer = Adam(lr=lr, clipnorm=0.001)\n",
        "\ttrain_model.compile(loss=dummy_loss, optimizer=optimizer)\n",
        "\treturn train_model, infer_model\n",
        "\n",
        "def main_train():\n",
        "\ttrain_ints, valid_ints, labels, max_box_per_image = create_training_instances(\n",
        "\t\tconfig['train']['train_annot_folder'],\n",
        "\t\tconfig['train']['train_image_folder'],\n",
        "\t\tconfig['train']['cache_name'],\n",
        "\t\tconfig['valid']['valid_annot_folder'],\n",
        "\t\tconfig['valid']['valid_image_folder'],\n",
        "\t\tconfig['valid']['cache_name'],\n",
        "\t\tconfig['model']['labels'])\n",
        "\tprint('\\nTraining on: \\t' + str(labels) + '\\n')\n",
        "\ttrain_generator = BatchGenerator(\n",
        "\t\tinstances           = train_ints,\n",
        "\t\tanchors             = config['model']['anchors'],\n",
        "\t\tlabels              = labels,\n",
        "\t\tdownsample          = 32,\n",
        "\t\tmax_box_per_image   = max_box_per_image,\n",
        "\t\tbatch_size          = config['train']['batch_size'],\n",
        "\t\tmin_net_size        = config['model']['min_input_size'],\n",
        "\t\tmax_net_size        = config['model']['max_input_size'],\n",
        "\t\tshuffle             = True,\n",
        "\t\tjitter              = 0.3,\n",
        "\t\tnorm                = normalize)\n",
        "\tvalid_generator = BatchGenerator(\n",
        "\t\tinstances           = valid_ints,\n",
        "\t\tanchors             = config['model']['anchors'],\n",
        "\t\tlabels              = labels,\n",
        "\t\tdownsample          = 32,\n",
        "\t\tmax_box_per_image   = max_box_per_image,\n",
        "\t\tbatch_size          = config['train']['batch_size'],\n",
        "\t\tmin_net_size        = config['model']['min_input_size'],\n",
        "\t\tmax_net_size        = config['model']['max_input_size'],\n",
        "\t\tshuffle             = True,\n",
        "\t\tjitter              = 0.0,\n",
        "\t\tnorm                = normalize)\n",
        "\tif os.path.exists(config['train']['saved_weights_name']):\n",
        "\t\tconfig['train']['warmup_epochs'] = 0\n",
        "\twarmup_batches = config['train']['warmup_epochs'] * (config['train']['train_times']*len(train_generator))\n",
        "\tos.environ['CUDA_VISIBLE_DEVICES'] = config['train']['gpus']\n",
        "\tmulti_gpu = len(config['train']['gpus'].split(','))\n",
        "\ttrain_model, infer_model = create_model(\n",
        "\t\tnb_class             = len(labels),\n",
        "\t\tanchors              = config['model']['anchors'],\n",
        "\t\tmax_box_per_image    = max_box_per_image,\n",
        "\t\tmax_grid             = [config['model']['max_input_size'], config['model']['max_input_size']],\n",
        "\t\tbatch_size           = config['train']['batch_size'],\n",
        "\t\twarmup_batches       = warmup_batches,\n",
        "\t\tignore_thresh        = config['train']['ignore_thresh'],\n",
        "\t\tmulti_gpu            = multi_gpu,\n",
        "\t\tsaved_weights_name   = config['train']['saved_weights_name'],\n",
        "\t\tlr                   = config['train']['learning_rate'],\n",
        "\t\tgrid_scales          = config['train']['grid_scales'],\n",
        "\t\tobj_scale            = config['train']['obj_scale'],\n",
        "\t\tnoobj_scale          = config['train']['noobj_scale'],\n",
        "\t\txywh_scale           = config['train']['xywh_scale'],\n",
        "\t\tclass_scale          = config['train']['class_scale'],)\n",
        "\tcallbacks = create_callbacks(config['train']['saved_weights_name'], config['train']['tensorboard_dir'], infer_model)\n",
        "\ttrain_model.fit_generator(\n",
        "\t\tgenerator           = train_generator,\n",
        "\t\tsteps_per_epoch     = len(train_generator) * config['train']['train_times'],\n",
        "\t\tepochs              = config['train']['nb_epochs'] + config['train']['warmup_epochs'],\n",
        "\t\tverbose             = 1,\n",
        "\t\tcallbacks           = callbacks,\n",
        "\t\tworkers             = 4,\n",
        "\t\tmax_queue_size      = 8)\n",
        "\tif multi_gpu > 1:\n",
        "\t\tinfer_model = load_model(config['train']['saved_weights_name'])\n",
        "\taverage_precisions = evaluate(infer_model, valid_generator)\n",
        "\tfor label, average_precision in average_precisions.items():\n",
        "\t\tprint(labels[label] + ': {:.4f}'.format(average_precision))\n",
        "\tprint('mAP: {:.4f}'.format(sum(average_precisions.values()) / len(average_precisions)))\n",
        "\n",
        "def main_predict(WEIGHTS, FILENAME, output_path):\n",
        "\tconfig_path\t\t= config\n",
        "\tinput_path\t\t= FILENAME\n",
        "\tnet_h, net_w = 416, 416\n",
        "\tobj_thresh, nms_thresh = 0.5, 0.45\n",
        "\tos.environ['CUDA_VISIBLE_DEVICES'] = config['train']['gpus']\n",
        "\tinfer_model = load_model(WEIGHTS)\n",
        "\tif 'webcam' in input_path:\n",
        "\t\tvideo_reader = cv2.VideoCapture(0)\n",
        "\t\tbatch_size   = 1\n",
        "\t\timages       = []\n",
        "\t\twhile True:\n",
        "\t\t\tret_val, image = video_reader.read()\n",
        "\t\t\tif ret_val == True: images += [image]\n",
        "\t\t\tif (len(images)==batch_size) or (ret_val==False and len(images)>0):\n",
        "\t\t\t\tbatch_boxes = get_yolo_boxes(infer_model, images, net_h, net_w, config['model']['anchors'], obj_thresh, nms_thresh)\n",
        "\t\t\t\tfor i in range(len(images)):\n",
        "\t\t\t\t\tdraw_boxes(images[i], batch_boxes[i], config['model']['labels'], obj_thresh)\n",
        "\t\t\t\t\tcv2.imshow('video with bboxes', images[i])\n",
        "\t\t\t\timages = []\n",
        "\t\t\tif cv2.waitKey(1) == 27:\n",
        "\t\t\t\tbreak \n",
        "\t\tcv2.destroyAllWindows()\n",
        "\telif input_path[-4:] == '.mp4':\n",
        "\t\tvideo_out = output_path + input_path.split('/')[-1]\n",
        "\t\tvideo_reader = cv2.VideoCapture(input_path)\n",
        "\t\tnb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\t\tframe_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\t\tframe_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "\t\tvideo_writer = cv2.VideoWriter(video_out, cv2.VideoWriter_fourcc(*'MPEG'), 50.0, (frame_w, frame_h))\n",
        "\t\tbatch_size  = 1\n",
        "\t\timages      = []\n",
        "\t\tstart_point = 0\n",
        "\t\tshow_window = False\n",
        "\t\tfor i in tqdm(range(nb_frames)):\n",
        "\t\t\t_, image = video_reader.read()\n",
        "\t\t\tif (float(i+1)/nb_frames) > start_point/100.:\n",
        "\t\t\t\timages += [image]\n",
        "\t\t\t\tif (i%batch_size == 0) or (i == (nb_frames-1) and len(images) > 0):\n",
        "\t\t\t\t\tbatch_boxes = get_yolo_boxes(infer_model, images, net_h, net_w, config['model']['anchors'], obj_thresh, nms_thresh)\n",
        "\t\t\t\t\tfor i in range(len(images)):\n",
        "\t\t\t\t\t\tdraw_boxes(images[i], batch_boxes[i], config['model']['labels'], obj_thresh)\n",
        "\t\t\t\t\t\tif show_window: cv2.imshow('video with bboxes', images[i])\n",
        "\t\t\t\t\t\tvideo_writer.write(images[i]) \n",
        "\t\t\t\t\timages = []\n",
        "\t\t\t\tif show_window and cv2.waitKey(1) == 27: break\n",
        "\t\tif show_window: cv2.destroyAllWindows()\n",
        "\t\tvideo_reader.release()\n",
        "\t\tvideo_writer.release()\n",
        "\telse:\n",
        "\t\timage_paths = []\n",
        "\t\tif os.path.isdir(input_path):\n",
        "\t\t\tfor inp_file in os.listdir(input_path):\n",
        "\t\t\t\timage_paths += [input_path + inp_file]\n",
        "\t\telse:\n",
        "\t\t\timage_paths += [input_path]\n",
        "\t\timage_paths = [inp_file for inp_file in image_paths if (inp_file[-4:] in ['.jpg', '.png', 'JPEG'])]\n",
        "\t\tfor image_path in image_paths:\n",
        "\t\t\timage = cv2.imread(image_path)\n",
        "\t\t\tboxes = get_yolo_boxes(infer_model, [image], net_h, net_w, config['model']['anchors'], obj_thresh, nms_thresh)[0]\n",
        "\t\t\tdraw_boxes(image, boxes, config['model']['labels'], obj_thresh)\n",
        "\t\t\tcv2.imwrite(output_path + image_path.split('/')[-1], np.uint8(image))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz5zaK9DR5Mg"
      },
      "source": [
        "# **Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0HpqARKR2SZ"
      },
      "source": [
        "import random\n",
        "from google.colab import files\n",
        "\n",
        "for i in range(20):\n",
        "    AFile = random.choice(os.listdir('./dataset'))\n",
        "    main_predict('weights.h5', './dataset/{}'.format(AFile), './')\n",
        "    print(AFile)\n",
        "!zip ./results.zip ./*.jpg\n",
        "files.download('./results.zip')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}